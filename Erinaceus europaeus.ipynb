{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Trigger the authentication flow.\n",
    "# ee.Authenticate()\n",
    "\n",
    "ee.Initialize(project='ee-arzaaan789')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-24T23:21:03.713861Z",
     "start_time": "2025-05-24T23:21:01.706708Z"
    }
   },
   "id": "6fbf115adb971a07"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/sggn66691kd6g5mtyzpq2hv80000gn/T/ipykernel_62969/233028871.py:4: DtypeWarning: Columns (2,10,16,29,36,37,38,39,40,41,44,45,46,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Erinaceus europaeus.csv\", delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"Erinaceus europaeus.csv\", delimiter='\\t')\n",
    "df = df[df[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "df = df[df['year']>=2022]\n",
    "# df['eventDate'] = df['eventDate'].str.replace('/','')\n",
    "df['eventDate'] = pd.to_datetime(df['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "df = df[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "df = df.dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-24T23:21:05.533156Z",
     "start_time": "2025-05-24T23:21:03.715208Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 924/924 [50:10<00:00,  3.26s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               species  decimalLatitude  decimalLongitude  eventDate  \\\n",
      "0  Erinaceus europaeus        52.835848         -0.947492 2022-06-19   \n",
      "1  Erinaceus europaeus        52.818132         -0.977597 2023-05-13   \n",
      "2  Erinaceus europaeus        52.689385         -0.684702 2022-06-12   \n",
      "3  Erinaceus europaeus        52.727454         -0.890871 2022-02-25   \n",
      "4  Erinaceus europaeus        52.710769         -1.039317 2022-07-13   \n",
      "\n",
      "        BSI         LST     MNDWI      NDBI      NDSI      NDVI      NDWI  \\\n",
      "0 -0.736822  297.235328 -0.500073 -0.255981 -0.500073  0.743785 -0.663119   \n",
      "1 -0.674325  293.872242 -0.457554 -0.257522 -0.457554  0.657087 -0.615822   \n",
      "2 -0.643783  294.579695 -0.459196 -0.202234 -0.459196  0.583621 -0.591600   \n",
      "3 -0.566207  282.179633 -0.483596 -0.024255 -0.483596  0.473914 -0.483627   \n",
      "4 -0.712308  304.672511 -0.574857 -0.196281 -0.574857  0.668698 -0.681336   \n",
      "\n",
      "       SAVI        UI  \n",
      "0  1.115571  0.255981  \n",
      "1  0.985519  0.257522  \n",
      "2  0.875334  0.202234  \n",
      "3  0.710765  0.024255  \n",
      "4  1.002917  0.196281  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ee.Initialize()\n",
    "\n",
    "# Your dataframe 'df' must have columns: decimalLongitude, decimalLatitude\n",
    "# Example: df = pd.read_csv(\"Erinaceus europaeus.csv\", delimiter='\\t')\n",
    "\n",
    "def create_aoi(lon, lat, box_size_km=1):\n",
    "    \"\"\"Create approx 1km x 1km square polygon around lon, lat.\"\"\"\n",
    "    half_side_deg = box_size_km / 111.32 / 2  # Rough approx degrees per km\n",
    "\n",
    "    coords = [\n",
    "        [lon - half_side_deg, lat - half_side_deg],\n",
    "        [lon + half_side_deg, lat - half_side_deg],\n",
    "        [lon + half_side_deg, lat + half_side_deg],\n",
    "        [lon - half_side_deg, lat + half_side_deg],\n",
    "        [lon - half_side_deg, lat - half_side_deg]\n",
    "    ]\n",
    "    return ee.Geometry.Polygon(coords)\n",
    "\n",
    "def compute_all_indices(feature, start_date, end_date):\n",
    "    \"\"\"Compute spectral indices and LST for one EE Feature (with AOI geometry).\"\"\"\n",
    "    aoi = feature.geometry()\n",
    "\n",
    "    s2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "          .filterBounds(aoi)\n",
    "          .filterDate(start_date, end_date)\n",
    "          .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
    "          .first())\n",
    "    s2 = ee.Image(s2).clip(aoi)\n",
    "\n",
    "    blue = s2.select('B2')\n",
    "    green = s2.select('B3')\n",
    "    red = s2.select('B4')\n",
    "    nir = s2.select('B8')\n",
    "    swir = s2.select('B11')\n",
    "\n",
    "    L = 0.5  # SAVI constant\n",
    "\n",
    "    ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
    "    ndwi = green.subtract(nir).divide(green.add(nir)).rename('NDWI')\n",
    "    ndbi = swir.subtract(nir).divide(swir.add(nir)).rename('NDBI')\n",
    "    savi = nir.subtract(red).divide(nir.add(red).add(L)).multiply(1 + L).rename('SAVI')\n",
    "    mndwi = green.subtract(swir).divide(green.add(swir)).rename('MNDWI')\n",
    "    ndsi = green.subtract(swir).divide(green.add(swir)).rename('NDSI')\n",
    "    bsi = (red.add(blue).subtract(nir.add(swir))).divide(red.add(blue).add(nir).add(swir)).rename('BSI')\n",
    "    ui = nir.subtract(swir).divide(nir.add(swir)).rename('UI')\n",
    "\n",
    "    reducers = ee.Reducer.mean()\n",
    "    scale_10m = 10\n",
    "\n",
    "    ndvi_mean = ndvi.reduceRegion(reducers, aoi, scale_10m).get('NDVI')\n",
    "    ndwi_mean = ndwi.reduceRegion(reducers, aoi, scale_10m).get('NDWI')\n",
    "    ndbi_mean = ndbi.reduceRegion(reducers, aoi, scale_10m).get('NDBI')\n",
    "    savi_mean = savi.reduceRegion(reducers, aoi, scale_10m).get('SAVI')\n",
    "    mndwi_mean = mndwi.reduceRegion(reducers, aoi, scale_10m).get('MNDWI')\n",
    "    ndsi_mean = ndsi.reduceRegion(reducers, aoi, scale_10m).get('NDSI')\n",
    "    bsi_mean = bsi.reduceRegion(reducers, aoi, scale_10m).get('BSI')\n",
    "    ui_mean = ui.reduceRegion(reducers, aoi, scale_10m).get('UI')\n",
    "\n",
    "    # MODIS LST dataset\n",
    "    modis = (ee.ImageCollection(\"MODIS/061/MOD11A1\")\n",
    "             .filterBounds(aoi)\n",
    "             .filterDate(start_date, end_date)\n",
    "             .select('LST_Day_1km'))\n",
    "\n",
    "    lst_mean_img = modis.mean().multiply(0.02).clip(aoi)\n",
    "\n",
    "    lst_mean = lst_mean_img.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi,\n",
    "        scale=1000\n",
    "    ).get('LST_Day_1km')\n",
    "\n",
    "    return feature.set({\n",
    "        'NDVI': ndvi_mean,\n",
    "        'NDWI': ndwi_mean,\n",
    "        'NDBI': ndbi_mean,\n",
    "        'SAVI': savi_mean,\n",
    "        'MNDWI': mndwi_mean,\n",
    "        'NDSI': ndsi_mean,\n",
    "        'BSI': bsi_mean,\n",
    "        'UI': ui_mean,\n",
    "        'LST': lst_mean\n",
    "    })\n",
    "\n",
    "# Split df into batches\n",
    "batch_size = 50\n",
    "batches = [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "index_names = ['NDVI', 'NDWI', 'NDBI', 'SAVI', 'MNDWI', 'NDSI', 'BSI', 'UI', 'LST']\n",
    "\n",
    "for batch in tqdm(batches, desc=\"Processing batches\"):\n",
    "    features = []\n",
    "    batch_indices = []\n",
    "    feature_metadata = {}\n",
    "\n",
    "    for idx, row in batch.iterrows():\n",
    "        \n",
    "        aoi = create_aoi(row['decimalLongitude'], row['decimalLatitude'])\n",
    "        feature = ee.Feature(aoi).set('index', idx)\n",
    "        features.append(feature)\n",
    "        batch_indices.append(idx)  # Save the original index\n",
    "        \n",
    "        event_date = row['eventDate']\n",
    "        start_date = (event_date - timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "        end_date = (event_date + timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "        feature_metadata[idx] = (start_date, end_date)\n",
    "\n",
    "    # Create a FeatureCollection from the list of features\n",
    "    fc = ee.FeatureCollection(features)\n",
    "    \n",
    "    # Define wrapper for map to inject per-feature dates\n",
    "    def map_with_dates(f):\n",
    "        idx = f.get('index')\n",
    "        # Use dictionary lookup to get dates for this feature\n",
    "        date_dict = ee.Dictionary(ee.Dictionary(feature_metadata))\n",
    "        dates = ee.List(date_dict.get(ee.Number(idx)))\n",
    "        return compute_all_indices(f, dates.get(0), dates.get(1))\n",
    "\n",
    "    try:\n",
    "        result_fc = fc.map(map_with_dates)\n",
    "        results = result_fc.getInfo()\n",
    "\n",
    "        rows = []\n",
    "        for f in results['features']:\n",
    "            props = f['properties']\n",
    "            rows.append(props)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch starting at index {batch.index[0]}: {e}\")\n",
    "        # If there's an error, create placeholder rows with None\n",
    "        rows = [{'index': i, **{name: None for name in index_names}} for i in batch_indices]\n",
    "\n",
    "    batch_results_df = pd.DataFrame(rows).sort_values('index').reset_index(drop=True)\n",
    "    results_list.append(batch_results_df)\n",
    "\n",
    "# Concatenate all batches and sort by original index\n",
    "all_results_df = pd.concat(results_list).sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Merge with original df\n",
    "df_final = pd.concat([df.reset_index(drop=True), all_results_df.drop(columns=['index'])], axis=1)\n",
    "\n",
    "print(df_final.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T00:11:16.626598Z",
     "start_time": "2025-05-24T23:21:05.548799Z"
    }
   },
   "id": "a6493957d4be9f9d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/sggn66691kd6g5mtyzpq2hv80000gn/T/ipykernel_62969/3683829675.py:7: DtypeWarning: Columns (10,16,39,41,45,46,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  badgers = pd.read_csv(\"Meles meles.csv\", delimiter='\\t')\n",
      "/var/folders/0n/sggn66691kd6g5mtyzpq2hv80000gn/T/ipykernel_62969/3683829675.py:14: DtypeWarning: Columns (2,10,36,38,39,41,45,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ground_beetles = pd.read_csv(\"ground_beetles.csv\", delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "df_final.to_csv(\"hedgehog_full_data.csv\", index=False)\n",
    "df = pd.read_csv(\"hedgehog_full_data.csv\")\n",
    "df['eventDate'] = pd.to_datetime(df['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "badgers = pd.read_csv(\"Meles meles.csv\", delimiter='\\t')\n",
    "badgers = badgers[badgers[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "badgers = badgers[badgers['year']>=2022]\n",
    "badgers['eventDate'] = pd.to_datetime(badgers['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "badgers = badgers[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "badgers = badgers.dropna().reset_index(drop=True)\n",
    "\n",
    "ground_beetles = pd.read_csv(\"ground_beetles.csv\", delimiter='\\t')\n",
    "ground_beetles = ground_beetles[ground_beetles[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "ground_beetles = ground_beetles[ground_beetles['year']>=2022]\n",
    "ground_beetles['eventDate'] = pd.to_datetime(ground_beetles['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "ground_beetles = ground_beetles[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "ground_beetles = ground_beetles.dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T00:11:18.825861Z",
     "start_time": "2025-05-25T00:11:16.629649Z"
    }
   },
   "id": "dfa3f8fbd86b40e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45912/45912 [00:04<00:00, 10843.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Convert lat/lon to radians for BallTree\n",
    "hedgehog_coords = np.deg2rad(df[['decimalLatitude', 'decimalLongitude']].values)\n",
    "badger_coords = np.deg2rad(badgers[['decimalLatitude', 'decimalLongitude']].values)\n",
    "ground_beetles_coords = np.deg2rad(ground_beetles[['decimalLatitude', 'decimalLongitude']].values)\n",
    "\n",
    "# Build BallTrees\n",
    "tree_badger = BallTree(badger_coords, metric='haversine')\n",
    "tree_ground_beetles = BallTree(ground_beetles_coords, metric='haversine')\n",
    "\n",
    "# 1 km radius in radians\n",
    "radius = 1 / 6371.0\n",
    "\n",
    "# Initialize presence columns\n",
    "df['badger_presence'] = 0\n",
    "df['ground_beetles_presence'] = 0\n",
    "\n",
    "# Iterate through each hedgehog point with tqdm for progress tracking\n",
    "for i in tqdm(range(len(df))):\n",
    "    point = hedgehog_coords[i].reshape(1, -1)\n",
    "    event_month = df.loc[i, 'eventDate'].month\n",
    "    event_year = df.loc[i, 'eventDate'].year\n",
    "\n",
    "    # BADGERS\n",
    "    idxs = tree_badger.query_radius(point, r=radius)[0]\n",
    "    for j in idxs:\n",
    "        badger_date = badgers.loc[j, 'eventDate']\n",
    "        if badger_date.month == event_month and badger_date.year == event_year:\n",
    "            df.at[i, 'badger_presence'] = 1\n",
    "            break  # Found at least one match, no need to check further\n",
    "\n",
    "    # GROUND BEETLES\n",
    "    idxs = tree_ground_beetles.query_radius(point, r=radius)[0]\n",
    "    for j in idxs:\n",
    "        beetle_date = ground_beetles.loc[j, 'eventDate']\n",
    "        if beetle_date.month == event_month and beetle_date.year == event_year:\n",
    "            df.at[i, 'ground_beetles_presence'] = 1\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T00:11:23.770659Z",
     "start_time": "2025-05-25T00:11:18.829441Z"
    }
   },
   "id": "e4d047d447e2eac8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 207/2551 [07:04<1:15:55,  1.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] No data elements in server response. Check query location/filters and log. — bbox: (np.float64(-5.32), np.float64(57.18), np.float64(-5.180000000000001), np.float64(57.32000000000001))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2551/2551 [3:06:08<00:00,  4.38s/it]   \n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Construct GeoDataFrame\n",
    "df['geometry'] = [Point(xy) for xy in zip(df['decimalLongitude'], df['decimalLatitude'])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# Define spatial tiling: 0.05 x 0.05 degrees\n",
    "tile_size = 0.1\n",
    "gdf['tile_x'] = (gdf['decimalLongitude'] // tile_size).astype(int)\n",
    "gdf['tile_y'] = (gdf['decimalLatitude'] // tile_size).astype(int)\n",
    "\n",
    "# Group by tile\n",
    "grouped = gdf.groupby(['tile_x', 'tile_y'])\n",
    "\n",
    "# Store results\n",
    "all_distances = []\n",
    "\n",
    "for (tile_x, tile_y), group in tqdm(grouped, total=len(grouped)):\n",
    "    west = tile_x * tile_size - 0.02\n",
    "    south = tile_y * tile_size - 0.02\n",
    "    east = (tile_x + 1) * tile_size + 0.02\n",
    "    north = (tile_y + 1) * tile_size + 0.02\n",
    "    bbox = (west, south, east, north)\n",
    "\n",
    "    try:\n",
    "        G = ox.graph_from_bbox(bbox, network_type='drive_service')\n",
    "        if len(G.nodes) == 0:\n",
    "            print(f\"[EMPTY GRAPH] bbox: {bbox}, skipping...\")\n",
    "            all_distances.extend([np.nan] * len(group))\n",
    "            continue\n",
    "\n",
    "        G_proj = ox.project_graph(G)\n",
    "        nodes_proj, edges_proj = ox.graph_to_gdfs(G_proj)\n",
    "        points_proj = group.geometry.to_crs(nodes_proj.crs)\n",
    "\n",
    "        for point_proj in points_proj:\n",
    "            try:\n",
    "                u, v, k = ox.distance.nearest_edges(G_proj, [point_proj.x], [point_proj.y])[0]\n",
    "                edge_geom = edges_proj.loc[(u, v, k)]['geometry']\n",
    "                distance = point_proj.distance(edge_geom)\n",
    "                all_distances.append(distance)\n",
    "            except Exception as e:\n",
    "                print(f\"  [Point ERROR] {e}\")\n",
    "                all_distances.append(np.nan)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[TILE ERROR] {e} — bbox: {bbox}\")\n",
    "        all_distances.extend([np.nan] * len(group))\n",
    "\n",
    "\n",
    "# Store back in original DataFrame order\n",
    "gdf['distance_to_road'] = all_distances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T03:17:33.413232Z",
     "start_time": "2025-05-25T00:11:23.772951Z"
    }
   },
   "id": "dce68175ecf2cb3e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "gdf['near_road'] = np.where(gdf['distance_to_road'] <= 500, 1, 0)        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T03:17:33.433620Z",
     "start_time": "2025-05-25T03:17:33.412395Z"
    }
   },
   "id": "593aa42f996890c6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "gdf=gdf.drop(['tile_x', 'tile_y', 'geometry', 'distance_to_road'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T03:17:33.453401Z",
     "start_time": "2025-05-25T03:17:33.433381Z"
    }
   },
   "id": "8962c70ac25f5419"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1720/45912 [00:04<01:41, 436.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2955/45912 [00:07<01:35, 451.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 13744/45912 [00:30<01:15, 425.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 14082/45912 [00:31<01:16, 414.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 14206/45912 [00:31<01:19, 397.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 1 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 15013/45912 [00:33<01:13, 421.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 16360/45912 [00:36<01:08, 432.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 16710/45912 [00:37<01:08, 427.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 16926/45912 [00:37<01:08, 425.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 18725/45912 [00:42<01:02, 434.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 18990/45912 [00:42<01:02, 433.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 19077/45912 [00:42<01:03, 424.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 20306/45912 [00:45<00:59, 430.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 20703/45912 [00:46<00:58, 433.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 21277/45912 [00:48<00:56, 432.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 21895/45912 [00:49<00:55, 433.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 21984/45912 [00:49<00:55, 431.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 24018/45912 [00:54<00:50, 436.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 24149/45912 [00:54<00:50, 428.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 24772/45912 [00:56<00:48, 439.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 25711/45912 [00:58<00:45, 439.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 26752/45912 [01:00<00:45, 425.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 27778/45912 [01:03<00:41, 434.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 1 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 28041/45912 [01:03<00:41, 433.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 28305/45912 [01:04<00:40, 429.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 29197/45912 [01:06<00:37, 443.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 31268/45912 [01:11<00:33, 436.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 31544/45912 [01:11<00:31, 455.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 32051/45912 [01:12<00:30, 457.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 32698/45912 [01:14<00:28, 456.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 32790/45912 [01:14<00:29, 447.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 33109/45912 [01:15<00:28, 446.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 1 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 33245/45912 [01:15<00:28, 444.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 33889/45912 [01:16<00:26, 455.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 34626/45912 [01:18<00:25, 449.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 34900/45912 [01:19<00:24, 449.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 35036/45912 [01:19<00:24, 438.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 35536/45912 [01:20<00:23, 447.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 37291/45912 [01:24<00:18, 454.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 37706/45912 [01:25<00:18, 455.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 38442/45912 [01:27<00:16, 455.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 38718/45912 [01:27<00:15, 452.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 41174/45912 [01:32<00:10, 457.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 44380/45912 [01:40<00:03, 455.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 45316/45912 [01:42<00:01, 431.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n",
      "Error processing row: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45912/45912 [01:44<00:00, 440.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "from rasterio.windows import Window\n",
    "import rasterio\n",
    "\n",
    "land_cover_map = {\n",
    "    1: \"Deciduous woodland\",\n",
    "    2: \"Coniferous woodland\",\n",
    "    3: \"Arable\",\n",
    "    4: \"Improved grassland\",\n",
    "    5: \"Neutral grassland\",\n",
    "    6: \"Calcareous grassland\",\n",
    "    7: \"Acid grassland\",\n",
    "    8: \"Fen\",\n",
    "    9: \"Heather\",\n",
    "    10: \"Heather grassland\",\n",
    "    11: \"Bog\",\n",
    "    12: \"Inland rock\",\n",
    "    13: \"Saltwater\",\n",
    "    14: \"Freshwater\",\n",
    "    15: \"Supralittoral rock\",\n",
    "    16: \"Supralittoral sediment\",\n",
    "    17: \"Littoral rock\",\n",
    "    18: \"Littoral sediment\",\n",
    "    19: \"Saltmarsh\",\n",
    "    20: \"Urban\",\n",
    "    21: \"Suburban\"\n",
    "}\n",
    "\n",
    "# Batch coordinate transformation\n",
    "transformer_ni = Transformer.from_crs(\"EPSG:4326\", \"EPSG:29903\", always_xy=True)\n",
    "transformer_gb = Transformer.from_crs(\"EPSG:4326\", \"EPSG:27700\", always_xy=True)\n",
    "\n",
    "coords = list(zip(gdf['decimalLongitude'], gdf['decimalLatitude']))\n",
    "gdf['easting_ni'], gdf['northing_ni'] = zip(*transformer_ni.itransform(coords))\n",
    "gdf['easting_gb'], gdf['northing_gb'] = zip(*transformer_gb.itransform(coords))\n",
    "\n",
    "# Raster processing optimization\n",
    "gb_raster = 'gblcm2023_10m.tif'\n",
    "n_ireland_raster = 'nilcm2023_10m.tif'\n",
    "\n",
    "\n",
    "def get_land_cover_class(row):\n",
    "    try:\n",
    "        # Try GB raster first\n",
    "        with rasterio.open(gb_raster) as src:\n",
    "            row_idx, col_idx = src.index(row['easting_gb'], row['northing_gb'])\n",
    "            # Read a small window around the point for better performance\n",
    "            window = Window(col_idx, row_idx, 1, 1)\n",
    "            land_cover_class = src.read(1, window=window)[0, 0]\n",
    "\n",
    "            if land_cover_class == 0:  # Check NI raster if GB is 0\n",
    "                with rasterio.open(n_ireland_raster) as src_ni:\n",
    "                    row_idx, col_idx = src_ni.index(row['easting_ni'], row['northing_ni'])\n",
    "                    window = Window(col_idx, row_idx, 1, 1)\n",
    "                    land_cover_class = src_ni.read(1, window=window)[0, 0]\n",
    "\n",
    "        return land_cover_map.get(land_cover_class, \"Unknown\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "gdf['Land_cover'] = gdf.progress_apply(get_land_cover_class, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T03:19:17.858237Z",
     "start_time": "2025-05-25T03:17:33.452639Z"
    }
   },
   "id": "a1be7a7ce34a0db9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "gdf = gdf.dropna()\n",
    "gdf=gdf.drop(['easting_ni', 'northing_ni', 'easting_gb', 'northing_gb'],axis=1)\n",
    "# Remove where Land_cover is Unknown\n",
    "gdf = gdf[gdf['Land_cover'] != \"Unknown\"].reset_index(drop=True)\n",
    "gdf.to_csv(\"hedgehog_final_data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T03:19:18.195931Z",
     "start_time": "2025-05-25T03:19:17.856569Z"
    }
   },
   "id": "fd81c793cbb83907"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "96f90652c8afcc81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
