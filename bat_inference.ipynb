{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-05T03:37:37.557195Z",
     "start_time": "2025-08-05T03:37:36.338088Z"
    }
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Trigger the authentication flow.\n",
    "# ee.Authenticate()\n",
    "\n",
    "ee.Initialize(project='ee-arzaaan789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "   decimalLongitude  decimalLatitude  eventDate\n0         -6.347425        49.893656 2025-06-01\n1         -6.333543        49.894177 2025-06-01\n2         -6.321265        49.912633 2025-06-01\n3         -6.307377        49.913150 2025-06-01\n4         -6.293488        49.913666 2025-06-01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>decimalLongitude</th>\n      <th>decimalLatitude</th>\n      <th>eventDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-6.347425</td>\n      <td>49.893656</td>\n      <td>2025-06-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-6.333543</td>\n      <td>49.894177</td>\n      <td>2025-06-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-6.321265</td>\n      <td>49.912633</td>\n      <td>2025-06-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-6.307377</td>\n      <td>49.913150</td>\n      <td>2025-06-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-6.293488</td>\n      <td>49.913666</td>\n      <td>2025-06-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"uk_grid_1000m.csv\")\n",
    "# rename longitude to 'decimalLongitude' and latitude to 'decimalLatitude'\n",
    "df.rename(columns={'longitude': 'decimalLongitude', 'latitude': 'decimalLatitude'}, inplace=True)\n",
    "# set eventDate to 1st May 2025\n",
    "df['eventDate'] = pd.to_datetime('2025-06-01')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T03:37:40.104270Z",
     "start_time": "2025-08-05T03:37:40.047607Z"
    }
   },
   "id": "6e89caae7120d78d"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 4888/4888 [13:49:26<00:00, 10.18s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decimalLongitude  decimalLatitude  eventDate       BSI         LST  \\\n",
      "0         -6.347425        49.893656 2025-06-01 -0.486515  289.980000   \n",
      "1         -6.333543        49.894177 2025-06-01 -0.533775         NaN   \n",
      "2         -6.321265        49.912633 2025-06-01 -0.444581  280.300000   \n",
      "3         -6.307377        49.913150 2025-06-01 -0.621371  289.999250   \n",
      "4         -6.293488        49.913666 2025-06-01 -0.719280  290.706667   \n",
      "\n",
      "      MNDWI      NDBI      NDSI      NDVI      NDWI      SAVI        UI  \n",
      "0 -0.283105 -0.237348 -0.283105  0.553412 -0.483623  0.829881  0.237348  \n",
      "1 -0.313951 -0.229969 -0.313951  0.601115 -0.508422  0.901449  0.229969  \n",
      "2 -0.233918 -0.242840 -0.233918  0.516397 -0.431643  0.774486  0.242840  \n",
      "3 -0.391363 -0.281401 -0.391363  0.663213 -0.594777  0.994679  0.281401  \n",
      "4 -0.463755 -0.323644 -0.463755  0.756636 -0.684624  1.134827  0.323644  \n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ee.Initialize()\n",
    "\n",
    "# Your dataframe 'df' must have columns: decimalLongitude, decimalLatitude\n",
    "# Example: df = pd.read_csv(\"Erinaceus europaeus.csv\", delimiter='\\t')\n",
    "\n",
    "def create_aoi(lon, lat, box_size_km=1):\n",
    "    \"\"\"Create approx 1km x 1km square polygon around lon, lat.\"\"\"\n",
    "    half_side_deg = box_size_km / 111.32 / 2  # Rough approx degrees per km\n",
    "\n",
    "    coords = [\n",
    "        [lon - half_side_deg, lat - half_side_deg],\n",
    "        [lon + half_side_deg, lat - half_side_deg],\n",
    "        [lon + half_side_deg, lat + half_side_deg],\n",
    "        [lon - half_side_deg, lat + half_side_deg],\n",
    "        [lon - half_side_deg, lat - half_side_deg]\n",
    "    ]\n",
    "    return ee.Geometry.Polygon(coords)\n",
    "\n",
    "def compute_all_indices(feature, start_date, end_date):\n",
    "    \"\"\"Compute spectral indices and LST for one EE Feature (with AOI geometry).\"\"\"\n",
    "    aoi = feature.geometry()\n",
    "\n",
    "    s2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "          .filterBounds(aoi)\n",
    "          .filterDate(start_date, end_date)\n",
    "          .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
    "          .first())\n",
    "    s2 = ee.Image(s2).clip(aoi)\n",
    "\n",
    "    blue = s2.select('B2')\n",
    "    green = s2.select('B3')\n",
    "    red = s2.select('B4')\n",
    "    nir = s2.select('B8')\n",
    "    swir = s2.select('B11')\n",
    "\n",
    "    L = 0.5  # SAVI constant\n",
    "\n",
    "    ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
    "    ndwi = green.subtract(nir).divide(green.add(nir)).rename('NDWI')\n",
    "    ndbi = swir.subtract(nir).divide(swir.add(nir)).rename('NDBI')\n",
    "    savi = nir.subtract(red).divide(nir.add(red).add(L)).multiply(1 + L).rename('SAVI')\n",
    "    mndwi = green.subtract(swir).divide(green.add(swir)).rename('MNDWI')\n",
    "    ndsi = green.subtract(swir).divide(green.add(swir)).rename('NDSI')\n",
    "    bsi = (red.add(blue).subtract(nir.add(swir))).divide(red.add(blue).add(nir).add(swir)).rename('BSI')\n",
    "    ui = nir.subtract(swir).divide(nir.add(swir)).rename('UI')\n",
    "\n",
    "    reducers = ee.Reducer.mean()\n",
    "    scale_10m = 1000\n",
    "\n",
    "    ndvi_mean = ndvi.reduceRegion(reducers, aoi, scale_10m).get('NDVI')\n",
    "    ndwi_mean = ndwi.reduceRegion(reducers, aoi, scale_10m).get('NDWI')\n",
    "    ndbi_mean = ndbi.reduceRegion(reducers, aoi, scale_10m).get('NDBI')\n",
    "    savi_mean = savi.reduceRegion(reducers, aoi, scale_10m).get('SAVI')\n",
    "    mndwi_mean = mndwi.reduceRegion(reducers, aoi, scale_10m).get('MNDWI')\n",
    "    ndsi_mean = ndsi.reduceRegion(reducers, aoi, scale_10m).get('NDSI')\n",
    "    bsi_mean = bsi.reduceRegion(reducers, aoi, scale_10m).get('BSI')\n",
    "    ui_mean = ui.reduceRegion(reducers, aoi, scale_10m).get('UI')\n",
    "\n",
    "    # MODIS LST dataset\n",
    "    modis = (ee.ImageCollection(\"MODIS/061/MOD11A1\")\n",
    "             .filterBounds(aoi)\n",
    "             .filterDate(start_date, end_date)\n",
    "             .select('LST_Day_1km'))\n",
    "\n",
    "    lst_mean_img = modis.mean().multiply(0.02).clip(aoi)\n",
    "\n",
    "    lst_mean = lst_mean_img.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi,\n",
    "        scale=1000\n",
    "    ).get('LST_Day_1km')\n",
    "\n",
    "    return feature.set({\n",
    "        'NDVI': ndvi_mean,\n",
    "        'NDWI': ndwi_mean,\n",
    "        'NDBI': ndbi_mean,\n",
    "        'SAVI': savi_mean,\n",
    "        'MNDWI': mndwi_mean,\n",
    "        'NDSI': ndsi_mean,\n",
    "        'BSI': bsi_mean,\n",
    "        'UI': ui_mean,\n",
    "        'LST': lst_mean\n",
    "    })\n",
    "\n",
    "# Split df into batches\n",
    "batch_size = 50\n",
    "batches = [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "index_names = ['NDVI', 'NDWI', 'NDBI', 'SAVI', 'MNDWI', 'NDSI', 'BSI', 'UI', 'LST']\n",
    "\n",
    "for batch in tqdm(batches, desc=\"Processing batches\"):\n",
    "    features = []\n",
    "    batch_indices = []\n",
    "    feature_metadata = {}\n",
    "\n",
    "    for idx, row in batch.iterrows():\n",
    "        \n",
    "        aoi = create_aoi(row['decimalLongitude'], row['decimalLatitude'])\n",
    "        feature = ee.Feature(aoi).set('index', idx)\n",
    "        features.append(feature)\n",
    "        batch_indices.append(idx)  # Save the original index\n",
    "        \n",
    "        event_date = row['eventDate']\n",
    "        start_date = (event_date - timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "        end_date = (event_date + timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "        feature_metadata[idx] = (start_date, end_date)\n",
    "\n",
    "    # Create a FeatureCollection from the list of features\n",
    "    fc = ee.FeatureCollection(features)\n",
    "    \n",
    "    # Define wrapper for map to inject per-feature dates\n",
    "    def map_with_dates(f):\n",
    "        idx = f.get('index')\n",
    "        # Use dictionary lookup to get dates for this feature\n",
    "        date_dict = ee.Dictionary(ee.Dictionary(feature_metadata))\n",
    "        dates = ee.List(date_dict.get(ee.Number(idx)))\n",
    "        return compute_all_indices(f, dates.get(0), dates.get(1))\n",
    "\n",
    "    try:\n",
    "        result_fc = fc.map(map_with_dates)\n",
    "        results = result_fc.getInfo()\n",
    "\n",
    "        rows = []\n",
    "        for f in results['features']:\n",
    "            props = f['properties']\n",
    "            rows.append(props)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch starting at index {batch.index[0]}: {e}\")\n",
    "        # If there's an error, create placeholder rows with None\n",
    "        rows = [{'index': i, **{name: None for name in index_names}} for i in batch_indices]\n",
    "\n",
    "    batch_results_df = pd.DataFrame(rows).sort_values('index').reset_index(drop=True)\n",
    "    results_list.append(batch_results_df)\n",
    "\n",
    "# Concatenate all batches and sort by original index\n",
    "all_results_df = pd.concat(results_list).sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Merge with original df\n",
    "df_final = pd.concat([df.reset_index(drop=True), all_results_df.drop(columns=['index'])], axis=1)\n",
    "\n",
    "print(df_final.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T17:27:17.090644Z",
     "start_time": "2025-08-05T03:37:47.873700Z"
    }
   },
   "id": "b84e6d60905e6b83"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "df_final.to_csv(\"bat_inference_data_indices.csv\", index=False)\n",
    "df = pd.read_csv(\"bat_inference_data_indices.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T17:39:19.287173Z",
     "start_time": "2025-08-05T17:39:13.932612Z"
    }
   },
   "id": "d959928cd321c596"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "ceratopogonidae = pd.read_csv(\"Ceratopogonidae.csv\", delimiter='\\t')\n",
    "ceratopogonidae = ceratopogonidae[ceratopogonidae[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "ceratopogonidae = ceratopogonidae[ceratopogonidae['year']>=2022]\n",
    "ceratopogonidae['eventDate'] = pd.to_datetime(ceratopogonidae['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "ceratopogonidae = ceratopogonidae[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "ceratopogonidae = ceratopogonidae.dropna().reset_index(drop=True)\n",
    "\n",
    "chironomidae = pd.read_csv(\"Chironomidae.csv\", delimiter='\\t')\n",
    "chironomidae = chironomidae[chironomidae[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "chironomidae = chironomidae[chironomidae['year']>=2022]\n",
    "chironomidae['eventDate'] = pd.to_datetime(chironomidae['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "chironomidae = chironomidae[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "chironomidae = chironomidae.dropna().reset_index(drop=True)\n",
    "\n",
    "cats = pd.read_csv(\"cats.csv\", delimiter='\\t')\n",
    "cats = cats[cats[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "cats = cats[cats['year']>=2022]\n",
    "cats['eventDate'] = pd.to_datetime(cats['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "cats = cats[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "cats = cats.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "wind_turbines = pd.read_excel(\"REPD_202407_WIND.xlsx\")\n",
    "wind_turbines = wind_turbines[wind_turbines['DEVSTATSHT']=='Operational']\n",
    "wind_turbines = wind_turbines[['LAT','LNG']]\n",
    "wind_turbines = wind_turbines.rename(columns={'LAT': 'decimalLatitude', 'LNG': 'decimalLongitude'})\n",
    "wind_turbines = wind_turbines.dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-05T17:27:17.218173Z"
    }
   },
   "id": "f2f1577e249ad617"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244359/244359 [00:30<00:00, 7911.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Convert lat/lon to radians for BallTree\n",
    "bat_coords = np.deg2rad(df[['decimalLatitude', 'decimalLongitude']].values)\n",
    "ceratopogonidae_coords = np.deg2rad(ceratopogonidae[['decimalLatitude', 'decimalLongitude']].values)\n",
    "chironomidae_coords = np.deg2rad(chironomidae[['decimalLatitude', 'decimalLongitude']].values)\n",
    "cats_coords = np.deg2rad(cats[['decimalLatitude', 'decimalLongitude']].values)\n",
    "wind_turbines_coords = np.deg2rad(wind_turbines[['decimalLatitude', 'decimalLongitude']].values)\n",
    "\n",
    "# Build BallTree using haversine metric\n",
    "tree_ceratopogonidae = BallTree(ceratopogonidae_coords, metric='haversine')\n",
    "tree_chironomidae = BallTree(chironomidae_coords, metric='haversine')\n",
    "tree_cats = BallTree(cats_coords, metric='haversine')\n",
    "tree_wind_turbines = BallTree(wind_turbines_coords, metric='haversine')\n",
    "\n",
    "# Define search radius: 1 km in radians\n",
    "earth_radius_km = 6371.0\n",
    "radius = 1 / earth_radius_km  # 1 km in radians\n",
    "\n",
    "# Initialize presence columns\n",
    "df['ceratopogonidae_presence'] = 0\n",
    "df['chironomidae_presence'] = 0\n",
    "df['cats_presence'] = 0\n",
    "\n",
    "# Iterate through each bat point with tqdm for progress tracking\n",
    "for i in tqdm(range(len(df))):\n",
    "    point = bat_coords[i].reshape(1, -1)\n",
    "    event_month = df.loc[i, 'eventDate'].month\n",
    "    event_year = df.loc[i, 'eventDate'].year\n",
    "\n",
    "    # CERATOPOGONIDAE\n",
    "    idxs = tree_ceratopogonidae.query_radius(point, r=radius)[0]\n",
    "    for j in idxs:\n",
    "        ceratopogonidae_date = ceratopogonidae.loc[j, 'eventDate']\n",
    "        if ceratopogonidae_date.month == event_month and ceratopogonidae_date.year == event_year:\n",
    "            df.at[i, 'ceratopogonidae_presence'] = 1\n",
    "            break  # Found at least one match, no need to check further\n",
    "\n",
    "    # CHIRONOMIDAE\n",
    "    idxs = tree_chironomidae.query_radius(point, r=radius)[0]\n",
    "    for j in idxs:\n",
    "        chironomidae_date = chironomidae.loc[j, 'eventDate']\n",
    "        if chironomidae_date.month == event_month and chironomidae_date.year == event_year:\n",
    "            df.at[i, 'chironomidae_presence'] = 1\n",
    "            break  # Found at least one match, no need to check further\n",
    "            \n",
    "    # CATS\n",
    "    idxs = tree_cats.query_radius(point, r=radius)[0]\n",
    "    for j in idxs:\n",
    "        cats_date = cats.loc[j, 'eventDate']\n",
    "        if cats_date.month == event_month and cats_date.year == event_year:\n",
    "            df.at[i, 'cats_presence'] = 1\n",
    "            break  # Found at least one match, no need to check further\n",
    "        \n",
    "indices = tree_wind_turbines.query_radius(bat_coords, r=radius)\n",
    "df['wind_turbines_presence'] = [1 if len(neighbors) > 0 else 0 for neighbors in indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-05T17:27:18.273114Z"
    }
   },
   "id": "c2d87eba673d1add"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/234672 [00:01<66:09:41,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] No data elements in server response. Check query location/filters and log. — bbox: (np.float64(-8.638), np.float64(57.82299999999999), np.float64(-8.616299999999999), np.float64(57.836))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/234672 [00:01<58:13:18,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] No data elements in server response. Check query location/filters and log. — bbox: (np.float64(-8.6223), np.float64(57.80499999999999), np.float64(-8.6006), np.float64(57.818))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/234672 [00:02<56:06:51,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] No data elements in server response. Check query location/filters and log. — bbox: (np.float64(-8.6223), np.float64(57.81399999999999), np.float64(-8.6006), np.float64(57.827))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/234672 [00:03<47:31:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.6066), np.float64(57.80499999999999), np.float64(-8.5849), np.float64(57.818))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/234672 [00:03<42:00:14,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.6066), np.float64(57.81399999999999), np.float64(-8.5849), np.float64(57.827))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/234672 [00:14<138:40:33,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.151299999999999), np.float64(54.42099999999999), np.float64(-8.1296), np.float64(54.434))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/234672 [00:22<99:17:01,  1.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.1356), np.float64(54.41199999999999), np.float64(-8.1139), np.float64(54.425))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/234672 [00:24<109:20:13,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.1356), np.float64(54.42099999999999), np.float64(-8.1139), np.float64(54.434))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/234672 [00:42<153:36:18,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.1199), np.float64(54.41199999999999), np.float64(-8.098199999999999), np.float64(54.425))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 53/234672 [01:41<136:37:24,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.072799999999999), np.float64(54.39399999999999), np.float64(-8.0511), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 57/234672 [01:49<165:53:18,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.072799999999999), np.float64(54.42999999999999), np.float64(-8.0511), np.float64(54.443))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 61/234672 [02:05<166:55:47,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.072799999999999), np.float64(54.465999999999994), np.float64(-8.0511), np.float64(54.479))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 67/234672 [03:25<569:09:56,  8.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.0571), np.float64(54.39399999999999), np.float64(-8.0354), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 73/234672 [03:33<125:25:56,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.0571), np.float64(54.44799999999999), np.float64(-8.0354), np.float64(54.461))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 81/234672 [03:49<103:40:16,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.0414), np.float64(54.38499999999999), np.float64(-8.019699999999998), np.float64(54.397999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 82/234672 [03:51<110:25:05,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.0414), np.float64(54.39399999999999), np.float64(-8.019699999999998), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 94/234672 [04:21<99:57:19,  1.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.0414), np.float64(54.501999999999995), np.float64(-8.019699999999998), np.float64(54.515))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 95/234672 [04:23<126:13:49,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.0414), np.float64(54.510999999999996), np.float64(-8.019699999999998), np.float64(54.524))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/234672 [04:32<140:34:49,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.025699999999999), np.float64(54.38499999999999), np.float64(-8.004), np.float64(54.397999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/234672 [04:34<131:49:14,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.025699999999999), np.float64(54.39399999999999), np.float64(-8.004), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 103/234672 [04:39<110:00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.025699999999999), np.float64(54.42099999999999), np.float64(-8.004), np.float64(54.434))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 105/234672 [04:41<95:50:31,  1.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.025699999999999), np.float64(54.43899999999999), np.float64(-8.004), np.float64(54.452))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 112/234672 [04:52<107:37:55,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.025699999999999), np.float64(54.501999999999995), np.float64(-8.004), np.float64(54.515))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 113/234672 [05:03<289:12:18,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.025699999999999), np.float64(54.510999999999996), np.float64(-8.004), np.float64(54.524))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 114/234672 [05:04<212:52:02,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.025699999999999), np.float64(54.519999999999996), np.float64(-8.004), np.float64(54.533))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 119/234672 [05:16<174:13:19,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.01), np.float64(54.38499999999999), np.float64(-7.988299999999999), np.float64(54.397999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 120/234672 [05:18<153:16:29,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.01), np.float64(54.39399999999999), np.float64(-7.988299999999999), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 121/234672 [05:18<118:23:23,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-8.01), np.float64(54.40299999999999), np.float64(-7.988299999999999), np.float64(54.416))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 125/234672 [05:29<162:55:35,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.01), np.float64(54.43899999999999), np.float64(-7.988299999999999), np.float64(54.452))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 126/234672 [05:34<209:13:02,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.01), np.float64(54.44799999999999), np.float64(-7.988299999999999), np.float64(54.461))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 133/234672 [05:47<99:08:06,  1.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-8.01), np.float64(54.510999999999996), np.float64(-7.988299999999999), np.float64(54.524))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 140/234672 [05:56<77:45:33,  1.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.994299999999999), np.float64(54.37599999999999), np.float64(-7.972599999999999), np.float64(54.388999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 141/234672 [06:08<282:16:58,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.994299999999999), np.float64(54.38499999999999), np.float64(-7.972599999999999), np.float64(54.397999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 142/234672 [06:09<215:56:35,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.994299999999999), np.float64(54.39399999999999), np.float64(-7.972599999999999), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 144/234672 [06:15<223:30:16,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-7.994299999999999), np.float64(54.41199999999999), np.float64(-7.972599999999999), np.float64(54.425))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 145/234672 [06:17<188:50:50,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-7.994299999999999), np.float64(54.42099999999999), np.float64(-7.972599999999999), np.float64(54.434))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 146/234672 [06:17<142:51:07,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.994299999999999), np.float64(54.42999999999999), np.float64(-7.972599999999999), np.float64(54.443))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 147/234672 [06:19<128:02:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.994299999999999), np.float64(54.43899999999999), np.float64(-7.972599999999999), np.float64(54.452))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 148/234672 [06:22<154:02:34,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.994299999999999), np.float64(54.44799999999999), np.float64(-7.972599999999999), np.float64(54.461))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 164/234672 [07:20<395:30:27,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.978599999999999), np.float64(54.37599999999999), np.float64(-7.956899999999999), np.float64(54.388999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 165/234672 [07:21<287:02:35,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.978599999999999), np.float64(54.38499999999999), np.float64(-7.956899999999999), np.float64(54.397999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 166/234672 [07:21<211:42:11,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.978599999999999), np.float64(54.39399999999999), np.float64(-7.956899999999999), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 167/234672 [07:22<158:56:03,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-7.978599999999999), np.float64(54.40299999999999), np.float64(-7.956899999999999), np.float64(54.416))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 168/234672 [07:22<121:02:42,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-7.978599999999999), np.float64(54.41199999999999), np.float64(-7.956899999999999), np.float64(54.425))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 170/234672 [07:29<199:37:06,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.978599999999999), np.float64(54.42999999999999), np.float64(-7.956899999999999), np.float64(54.443))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 171/234672 [07:31<169:44:28,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.978599999999999), np.float64(54.43899999999999), np.float64(-7.956899999999999), np.float64(54.452))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 172/234672 [07:32<130:10:27,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-7.978599999999999), np.float64(54.44799999999999), np.float64(-7.956899999999999), np.float64(54.461))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 176/234672 [07:48<234:57:21,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Graph contains no edges. — bbox: (np.float64(-7.978599999999999), np.float64(54.483999999999995), np.float64(-7.956899999999999), np.float64(54.497))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 182/234672 [08:01<183:38:56,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.303999999999995), np.float64(-7.941199999999999), np.float64(54.317))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 190/234672 [08:19<121:56:24,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.37599999999999), np.float64(-7.941199999999999), np.float64(54.388999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 191/234672 [08:24<185:12:03,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.38499999999999), np.float64(-7.941199999999999), np.float64(54.397999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 192/234672 [08:26<152:02:12,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.39399999999999), np.float64(-7.941199999999999), np.float64(54.407))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 193/234672 [08:26<115:15:21,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.40299999999999), np.float64(-7.941199999999999), np.float64(54.416))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 194/234672 [08:29<135:45:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.41199999999999), np.float64(-7.941199999999999), np.float64(54.425))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 195/234672 [08:31<138:07:14,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.42099999999999), np.float64(-7.941199999999999), np.float64(54.434))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 196/234672 [08:34<160:47:45,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.42999999999999), np.float64(-7.941199999999999), np.float64(54.443))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 197/234672 [08:36<149:52:07,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.43899999999999), np.float64(-7.941199999999999), np.float64(54.452))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 199/234672 [08:40<129:39:09,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.456999999999994), np.float64(-7.941199999999999), np.float64(54.47))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 200/234672 [08:43<151:35:23,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.465999999999994), np.float64(-7.941199999999999), np.float64(54.479))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 201/234672 [08:46<162:09:01,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.474999999999994), np.float64(-7.941199999999999), np.float64(54.488))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 202/234672 [08:48<157:11:49,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.483999999999995), np.float64(-7.941199999999999), np.float64(54.497))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 206/234672 [09:07<220:22:58,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.962899999999999), np.float64(54.519999999999996), np.float64(-7.941199999999999), np.float64(54.533))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 209/234672 [09:25<357:59:02,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.9472), np.float64(54.321999999999996), np.float64(-7.9254999999999995), np.float64(54.335))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 210/234672 [09:26<264:26:30,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.9472), np.float64(54.330999999999996), np.float64(-7.9254999999999995), np.float64(54.344))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 211/234672 [09:27<202:36:15,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.9472), np.float64(54.339999999999996), np.float64(-7.9254999999999995), np.float64(54.353))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 212/234672 [09:27<153:15:10,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.9472), np.float64(54.349), np.float64(-7.9254999999999995), np.float64(54.362))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 214/234672 [09:34<173:16:10,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.9472), np.float64(54.36699999999999), np.float64(-7.9254999999999995), np.float64(54.379999999999995))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 215/234672 [09:35<133:31:40,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.9472), np.float64(54.37599999999999), np.float64(-7.9254999999999995), np.float64(54.388999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 216/234672 [09:35<102:14:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TILE ERROR] Found no graph nodes within the requested polygon. — bbox: (np.float64(-7.9472), np.float64(54.38499999999999), np.float64(-7.9254999999999995), np.float64(54.397999999999996))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 216/234672 [09:39<174:38:39,  2.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 35\u001B[0m\n\u001B[1;32m     31\u001B[0m bbox \u001B[38;5;241m=\u001B[39m (west, south, east, north)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 35\u001B[0m     G \u001B[38;5;241m=\u001B[39m \u001B[43mox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph_from_bbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnetwork_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdrive_service\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(G\u001B[38;5;241m.\u001B[39mnodes) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[EMPTY GRAPH] bbox: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbbox\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, skipping...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/osmnx/graph.py:105\u001B[0m, in \u001B[0;36mgraph_from_bbox\u001B[0;34m(bbox, network_type, simplify, retain_all, truncate_by_edge, custom_filter)\u001B[0m\n\u001B[1;32m    102\u001B[0m polygon \u001B[38;5;241m=\u001B[39m utils_geo\u001B[38;5;241m.\u001B[39mbbox_to_poly(bbox)\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# create graph using this polygon geometry\u001B[39;00m\n\u001B[0;32m--> 105\u001B[0m G \u001B[38;5;241m=\u001B[39m \u001B[43mgraph_from_polygon\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpolygon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnetwork_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnetwork_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[43msimplify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msimplify\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_all\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretain_all\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncate_by_edge\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncate_by_edge\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_from_bbox returned graph with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(G)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m nodes and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(G\u001B[38;5;241m.\u001B[39medges)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m edges\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    115\u001B[0m utils\u001B[38;5;241m.\u001B[39mlog(msg, level\u001B[38;5;241m=\u001B[39mlg\u001B[38;5;241m.\u001B[39mINFO)\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/osmnx/graph.py:495\u001B[0m, in \u001B[0;36mgraph_from_polygon\u001B[0;34m(polygon, network_type, simplify, retain_all, truncate_by_edge, custom_filter)\u001B[0m\n\u001B[1;32m    493\u001B[0m \u001B[38;5;66;03m# create buffered graph from the downloaded data\u001B[39;00m\n\u001B[1;32m    494\u001B[0m bidirectional \u001B[38;5;241m=\u001B[39m network_type \u001B[38;5;129;01min\u001B[39;00m settings\u001B[38;5;241m.\u001B[39mbidirectional_network_types\n\u001B[0;32m--> 495\u001B[0m G_buff \u001B[38;5;241m=\u001B[39m \u001B[43m_create_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse_jsons\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbidirectional\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;66;03m# truncate buffered graph to the buffered polygon and retain_all for\u001B[39;00m\n\u001B[1;32m    498\u001B[0m \u001B[38;5;66;03m# now. needed because overpass returns entire ways that also include\u001B[39;00m\n\u001B[1;32m    499\u001B[0m \u001B[38;5;66;03m# nodes outside the poly if the way (that is, a way with a single OSM\u001B[39;00m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;66;03m# ID) has a node inside the poly at some point.\u001B[39;00m\n\u001B[1;32m    501\u001B[0m G_buff \u001B[38;5;241m=\u001B[39m truncate\u001B[38;5;241m.\u001B[39mtruncate_graph_polygon(G_buff, poly_buff, truncate_by_edge\u001B[38;5;241m=\u001B[39mtruncate_by_edge)\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/osmnx/graph.py:624\u001B[0m, in \u001B[0;36m_create_graph\u001B[0;34m(response_jsons, bidirectional)\u001B[0m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;66;03m# consume response_jsons generator to download data from server. if\u001B[39;00m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;66;03m# cache_only_mode, just consume response_jsons then continue next loop.\u001B[39;00m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;66;03m# otherwise, extract nodes and paths from the downloaded OSM data.\u001B[39;00m\n\u001B[1;32m    623\u001B[0m response_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 624\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse_json\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse_jsons\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_count\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m    626\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_only_mode\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/osmnx/_overpass.py:398\u001B[0m, in \u001B[0;36m_download_overpass_network\u001B[0;34m(polygon, network_type, custom_filter)\u001B[0m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m way_filter \u001B[38;5;129;01min\u001B[39;00m way_filters:\n\u001B[1;32m    397\u001B[0m     query_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moverpass_settings\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m;(way\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mway_filter\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m(poly:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpolygon_coord_str\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m);>;);out;\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 398\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[43m_overpass_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mOrderedDict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_str\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/osmnx/_overpass.py:465\u001B[0m, in \u001B[0;36m_overpass_request\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    463\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPost \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprepared_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with timeout=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msettings\u001B[38;5;241m.\u001B[39mrequests_timeout\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    464\u001B[0m utils\u001B[38;5;241m.\u001B[39mlog(msg, level\u001B[38;5;241m=\u001B[39mlg\u001B[38;5;241m.\u001B[39mINFO)\n\u001B[0;32m--> 465\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    466\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequests_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_http\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_http_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequests_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    471\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;66;03m# handle 429 and 504 errors by pausing then recursively re-trying request\u001B[39;00m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m429\u001B[39m, \u001B[38;5;241m504\u001B[39m}:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/requests/api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[0;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/requests/sessions.py:575\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    562\u001B[0m \u001B[38;5;66;03m# Create the Request.\u001B[39;00m\n\u001B[1;32m    563\u001B[0m req \u001B[38;5;241m=\u001B[39m Request(\n\u001B[1;32m    564\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod\u001B[38;5;241m.\u001B[39mupper(),\n\u001B[1;32m    565\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    573\u001B[0m     hooks\u001B[38;5;241m=\u001B[39mhooks,\n\u001B[1;32m    574\u001B[0m )\n\u001B[0;32m--> 575\u001B[0m prep \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m proxies \u001B[38;5;241m=\u001B[39m proxies \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m    579\u001B[0m settings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmerge_environment_settings(\n\u001B[1;32m    580\u001B[0m     prep\u001B[38;5;241m.\u001B[39murl, proxies, stream, verify, cert\n\u001B[1;32m    581\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/requests/sessions.py:484\u001B[0m, in \u001B[0;36mSession.prepare_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    481\u001B[0m     auth \u001B[38;5;241m=\u001B[39m get_netrc_auth(request\u001B[38;5;241m.\u001B[39murl)\n\u001B[1;32m    483\u001B[0m p \u001B[38;5;241m=\u001B[39m PreparedRequest()\n\u001B[0;32m--> 484\u001B[0m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupper\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCaseInsensitiveDict\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcookies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerged_cookies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_hooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhooks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/requests/models.py:370\u001B[0m, in \u001B[0;36mPreparedRequest.prepare\u001B[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001B[0m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_headers(headers)\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_cookies(cookies)\n\u001B[0;32m--> 370\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_auth(auth, url)\n\u001B[1;32m    373\u001B[0m \u001B[38;5;66;03m# Note that prepare_auth must be last to enable authentication schemes\u001B[39;00m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;66;03m# such as OAuth to work on a fully prepared request.\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# This MUST go after prepare_auth. Authenticators could add a hook\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/requests/models.py:558\u001B[0m, in \u001B[0;36mPreparedRequest.prepare_body\u001B[0;34m(self, data, files, json)\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    557\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[0;32m--> 558\u001B[0m         body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_encode_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    559\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, basestring) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(data, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    560\u001B[0m             content_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/requests/models.py:132\u001B[0m, in \u001B[0;36mRequestEncodingMixin._encode_params\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    125\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    126\u001B[0m                 result\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    127\u001B[0m                     (\n\u001B[1;32m    128\u001B[0m                         k\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(k, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m k,\n\u001B[1;32m    129\u001B[0m                         v\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m v,\n\u001B[1;32m    130\u001B[0m                     )\n\u001B[1;32m    131\u001B[0m                 )\n\u001B[0;32m--> 132\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43murlencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdoseq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py:1008\u001B[0m, in \u001B[0;36murlencode\u001B[0;34m(query, doseq, safe, encoding, errors, quote_via)\u001B[0m\n\u001B[1;32m   1005\u001B[0m     k \u001B[38;5;241m=\u001B[39m quote_via(\u001B[38;5;28mstr\u001B[39m(k), safe, encoding, errors)\n\u001B[1;32m   1007\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m-> 1008\u001B[0m     v \u001B[38;5;241m=\u001B[39m \u001B[43mquote_via\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1009\u001B[0m     l\u001B[38;5;241m.\u001B[39mappend(k \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m v)\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py:918\u001B[0m, in \u001B[0;36mquote_plus\u001B[0;34m(string, safe, encoding, errors)\u001B[0m\n\u001B[1;32m    916\u001B[0m     space \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    917\u001B[0m string \u001B[38;5;241m=\u001B[39m quote(string, safe \u001B[38;5;241m+\u001B[39m space, encoding, errors)\n\u001B[0;32m--> 918\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstring\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Construct GeoDataFrame\n",
    "df['geometry'] = [Point(xy) for xy in zip(df['decimalLongitude'], df['decimalLatitude'])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# Define spatial tiling: 0.05 x 0.05 degrees\n",
    "tile_size_lat = 0.009   # ~1 km in latitude degrees\n",
    "tile_size_lon = 0.0157  # ~1 km in longitude degrees\n",
    "padding_lat = 0.002  # ~200m latitude padding\n",
    "padding_lon = 0.003  # ~200-300m longitude padding\n",
    "\n",
    "gdf['tile_x'] = (gdf['decimalLongitude'] // tile_size_lon).astype(int)\n",
    "gdf['tile_y'] = (gdf['decimalLatitude'] // tile_size_lat).astype(int)\n",
    "\n",
    "# Group by tile\n",
    "grouped = gdf.groupby(['tile_x', 'tile_y'])\n",
    "\n",
    "# Store results\n",
    "all_distances = []\n",
    "\n",
    "for (tile_x, tile_y), group in tqdm(grouped, total=len(grouped)):\n",
    "    west = tile_x * tile_size_lon - padding_lon\n",
    "    south = tile_y * tile_size_lat - padding_lat\n",
    "    east = (tile_x + 1) * tile_size_lon + padding_lon\n",
    "    north = (tile_y + 1) * tile_size_lat + padding_lat\n",
    "    bbox = (west, south, east, north)\n",
    "\n",
    "\n",
    "    try:\n",
    "        G = ox.graph_from_bbox(bbox, network_type='drive_service')\n",
    "        if len(G.nodes) == 0:\n",
    "            print(f\"[EMPTY GRAPH] bbox: {bbox}, skipping...\")\n",
    "            all_distances.extend([np.nan] * len(group))\n",
    "            continue\n",
    "\n",
    "        G_proj = ox.project_graph(G)\n",
    "        nodes_proj, edges_proj = ox.graph_to_gdfs(G_proj)\n",
    "        points_proj = group.geometry.to_crs(nodes_proj.crs)\n",
    "\n",
    "        for point_proj in points_proj:\n",
    "            try:\n",
    "                u, v, k = ox.distance.nearest_edges(G_proj, [point_proj.x], [point_proj.y])[0]\n",
    "                edge_geom = edges_proj.loc[(u, v, k)]['geometry']\n",
    "                distance = point_proj.distance(edge_geom)\n",
    "                all_distances.append(distance)\n",
    "            except Exception as e:\n",
    "                print(f\"  [Point ERROR] {e}\")\n",
    "                all_distances.append(np.nan)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[TILE ERROR] {e} — bbox: {bbox}\")\n",
    "        all_distances.extend([np.nan] * len(group))\n",
    "\n",
    "\n",
    "# Store back in original DataFrame order\n",
    "gdf['distance_to_road'] = all_distances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T17:37:37.114625Z",
     "start_time": "2025-08-05T17:27:50.636239Z"
    }
   },
   "id": "c929cae40998095f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf['near_road'] = np.where(gdf['distance_to_road'] <= 500, 1, 0)        \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T17:37:37.290998Z",
     "start_time": "2025-08-05T17:37:37.135522Z"
    }
   },
   "id": "6160e77b803267a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf=gdf.drop(['tile_x', 'tile_y', 'geometry', 'distance_to_road'], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-05T17:37:37.148226Z"
    }
   },
   "id": "705bb42f065988f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "from rasterio.windows import Window\n",
    "import rasterio\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "land_cover_map = {\n",
    "    1: \"Deciduous woodland\",\n",
    "    2: \"Coniferous woodland\",\n",
    "    3: \"Arable\",\n",
    "    4: \"Improved grassland\",\n",
    "    5: \"Neutral grassland\",\n",
    "    6: \"Calcareous grassland\",\n",
    "    7: \"Acid grassland\",\n",
    "    8: \"Fen\",\n",
    "    9: \"Heather\",\n",
    "    10: \"Heather grassland\",\n",
    "    11: \"Bog\",\n",
    "    12: \"Inland rock\",\n",
    "    13: \"Saltwater\",\n",
    "    14: \"Freshwater\",\n",
    "    15: \"Supralittoral rock\",\n",
    "    16: \"Supralittoral sediment\",\n",
    "    17: \"Littoral rock\",\n",
    "    18: \"Littoral sediment\",\n",
    "    19: \"Saltmarsh\",\n",
    "    20: \"Urban\",\n",
    "    21: \"Suburban\"\n",
    "}\n",
    "\n",
    "# Batch coordinate transformation\n",
    "transformer_ni = Transformer.from_crs(\"EPSG:4326\", \"EPSG:29903\", always_xy=True)\n",
    "transformer_gb = Transformer.from_crs(\"EPSG:4326\", \"EPSG:27700\", always_xy=True)\n",
    "\n",
    "coords = list(zip(gdf['decimalLongitude'], gdf['decimalLatitude']))\n",
    "gdf['easting_ni'], gdf['northing_ni'] = zip(*transformer_ni.itransform(coords))\n",
    "gdf['easting_gb'], gdf['northing_gb'] = zip(*transformer_gb.itransform(coords))\n",
    "\n",
    "# Raster processing optimization\n",
    "gb_raster = 'gblcm2023_10m.tif'\n",
    "n_ireland_raster = 'nilcm2023_10m.tif'\n",
    "\n",
    "\n",
    "def get_land_cover_class_1km(row):\n",
    "    try:\n",
    "        window_size_pixels = 100  # 1 km / 10m resolution\n",
    "\n",
    "        # Open GB raster and read 1km x 1km window\n",
    "        with rasterio.open(gb_raster) as src:\n",
    "            row_idx, col_idx = src.index(row['easting_gb'], row['northing_gb'])\n",
    "\n",
    "            # Calculate window bounds, making sure not to go out of raster bounds\n",
    "            row_start = max(row_idx - window_size_pixels // 2, 0)\n",
    "            col_start = max(col_idx - window_size_pixels // 2, 0)\n",
    "\n",
    "            # Adjust window size if near edges\n",
    "            height = min(window_size_pixels, src.height - row_start)\n",
    "            width = min(window_size_pixels, src.width - col_start)\n",
    "\n",
    "            window = Window(col_start, row_start, width, height)\n",
    "            data = src.read(1, window=window)\n",
    "\n",
    "            # If all zero (or no data), fallback to NI raster\n",
    "            if np.all(data == 0):\n",
    "                with rasterio.open(n_ireland_raster) as src_ni:\n",
    "                    row_idx_ni, col_idx_ni = src_ni.index(row['easting_ni'], row['northing_ni'])\n",
    "\n",
    "                    row_start_ni = max(row_idx_ni - window_size_pixels // 2, 0)\n",
    "                    col_start_ni = max(col_idx_ni - window_size_pixels // 2, 0)\n",
    "\n",
    "                    height_ni = min(window_size_pixels, src_ni.height - row_start_ni)\n",
    "                    width_ni = min(window_size_pixels, src_ni.width - col_start_ni)\n",
    "\n",
    "                    window_ni = Window(col_start_ni, row_start_ni, width_ni, height_ni)\n",
    "                    data_ni = src_ni.read(1, window=window_ni)\n",
    "\n",
    "                    data = data_ni\n",
    "\n",
    "            # Find the most common class (mode) ignoring zeros (assuming 0 means no data)\n",
    "            unique, counts = np.unique(data[data != 0], return_counts=True)\n",
    "            if len(counts) == 0:\n",
    "                return \"Unknown\"\n",
    "\n",
    "            mode_class = unique[np.argmax(counts)]\n",
    "            return land_cover_map.get(mode_class, \"Unknown\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "gdf['Land_cover'] = gdf.progress_apply(get_land_cover_class_1km, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-05T17:37:37.154046Z"
    }
   },
   "id": "b10f99b184d92bea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf = gdf.dropna()\n",
    "gdf=gdf.drop(['easting_ni', 'northing_ni', 'easting_gb', 'northing_gb'],axis=1)\n",
    "# Remove where Land_cover is Unknown\n",
    "gdf = gdf[gdf['Land_cover'] != \"Unknown\"].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-05T17:37:37.164523Z"
    }
   },
   "id": "20f8148bb3c1cdab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf = gdf.dropna()\n",
    "gdf = gdf.drop_duplicates()\n",
    "gdf = gdf.drop(columns=['eventDate', 'species'])\n",
    "gdf = gdf.drop(columns=['decimalLatitude', 'decimalLongitude'])\n",
    "bat_bool_columns = ['ceratopogonidae_presence','chironomidae_presence','cats_presence','wind_turbines_presence','near_road']\n",
    "gdf[bat_bool_columns] = gdf[bat_bool_columns].astype(bool)\n",
    "gdf = pd.get_dummies(gdf, columns=['Land_cover'])\n",
    "gdf.to_csv(\"bat_inference_data_preprocessed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-05T17:37:37.169866Z"
    }
   },
   "id": "a36db77ca2ba4fa0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bat = pd.read_csv(\"bat_inference_data_preprocessed.csv\")\n",
    "bat = bat.astype({col: 'int' for col in bat.select_dtypes(include='bool').columns})\n",
    "\n",
    "#read scaler from bat_scaler.pkl\n",
    "import joblib\n",
    "scaler = joblib.load(\"bat_scaler.pkl\")\n",
    "# Scale the data\n",
    "# bat_scaled = scaler.transform(bat.drop(columns=['index']))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19a12e6bbc139c04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
