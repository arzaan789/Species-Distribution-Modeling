{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:55.345718Z",
     "start_time": "2025-06-15T02:54:55.174827Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "bat = pd.read_csv(\"bat_final_data.csv\")\n",
    "brown_hare = pd.read_csv(\"brown_hare_final_data.csv\")\n",
    "dormice = pd.read_csv(\"dormice_final_data.csv\")\n",
    "hedgehog = pd.read_csv(\"hedgehog_final_data.csv\")\n",
    "red_squirrel = pd.read_csv(\"red_squirrel_final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# drop na and duplicates\n",
    "bat = bat.dropna(subset=['decimalLatitude', 'decimalLongitude'])\n",
    "bat = bat.drop_duplicates(subset=['decimalLatitude', 'decimalLongitude', 'eventDate'])\n",
    "brown_hare = brown_hare.dropna(subset=['decimalLatitude', 'decimalLongitude'])\n",
    "brown_hare = brown_hare.drop_duplicates(subset=['decimalLatitude', 'decimalLongitude', 'eventDate'])\n",
    "dormice = dormice.dropna(subset=['decimalLatitude', 'decimalLongitude'])\n",
    "dormice = dormice.drop_duplicates(subset=['decimalLatitude', 'decimalLongitude', 'eventDate'])\n",
    "hedgehog = hedgehog.dropna(subset=['decimalLatitude', 'decimalLongitude'])\n",
    "hedgehog = hedgehog.drop_duplicates(subset=['decimalLatitude', 'decimalLongitude', 'eventDate'])\n",
    "red_squirrel = red_squirrel.dropna(subset=['decimalLatitude', 'decimalLongitude'])\n",
    "red_squirrel = red_squirrel.drop_duplicates(subset=['decimalLatitude', 'decimalLongitude', 'eventDate'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:55.370562Z",
     "start_time": "2025-06-15T02:54:55.348516Z"
    }
   },
   "id": "6e2fb50d8077974d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# time-based features\n",
    "\n",
    "bat['eventDate'] = pd.to_datetime(bat['eventDate'])\n",
    "bat['month'] = bat['eventDate'].dt.month\n",
    "bat['day_of_year'] = bat['eventDate'].dt.dayofyear\n",
    "\n",
    "brown_hare['eventDate'] = pd.to_datetime(brown_hare['eventDate'])\n",
    "brown_hare['month'] = brown_hare['eventDate'].dt.month\n",
    "brown_hare['day_of_year'] = brown_hare['eventDate'].dt.dayofyear\n",
    "\n",
    "dormice['eventDate'] = pd.to_datetime(dormice['eventDate'])\n",
    "dormice['month'] = dormice['eventDate'].dt.month\n",
    "dormice['day_of_year'] = dormice['eventDate'].dt.dayofyear\n",
    "\n",
    "hedgehog['eventDate'] = pd.to_datetime(hedgehog['eventDate'])\n",
    "hedgehog['month'] = hedgehog['eventDate'].dt.month\n",
    "hedgehog['day_of_year'] = hedgehog['eventDate'].dt.dayofyear\n",
    "\n",
    "red_squirrel['eventDate'] = pd.to_datetime(red_squirrel['eventDate'])\n",
    "red_squirrel['month'] = red_squirrel['eventDate'].dt.month\n",
    "red_squirrel['day_of_year'] = red_squirrel['eventDate'].dt.dayofyear"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:55.462398Z",
     "start_time": "2025-06-15T02:54:55.443723Z"
    }
   },
   "id": "187e6a6619ede907"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "#drop date and species name\n",
    "bat = bat.drop(columns=['eventDate', 'species'])\n",
    "brown_hare = brown_hare.drop(columns=['eventDate', 'species'])\n",
    "dormice = dormice.drop(columns=['eventDate', 'species'])\n",
    "hedgehog = hedgehog.drop(columns=['eventDate', 'species'])\n",
    "red_squirrel = red_squirrel.drop(columns=['eventDate', 'species'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:55.563218Z",
     "start_time": "2025-06-15T02:54:55.558293Z"
    }
   },
   "id": "dc01415436ee63cd"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Bat region clustering\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(bat, geometry=gpd.points_from_xy(bat['decimalLongitude'], bat['decimalLatitude']), crs='EPSG:4326')\n",
    "\n",
    "utm_crs = CRS(\"EPSG:32630\")\n",
    "gdf_utm = gdf.to_crs(utm_crs)\n",
    "\n",
    "# Extract UTM X/Y for clustering\n",
    "coords_utm = gdf_utm.geometry.apply(lambda p: (p.x, p.y)).to_list()\n",
    "\n",
    "\n",
    "# HDBSCAN clustering\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,       # ensures even sparse regions form clusters\n",
    "    min_samples=1,\n",
    "    cluster_selection_epsilon=800.0,  # 800 meters\n",
    "    metric='euclidean'  # Now in meters, not degrees\n",
    ")\n",
    "\n",
    "# Fit and assign region IDs\n",
    "labels = clusterer.fit_predict(np.array(coords_utm))\n",
    "\n",
    "# Assuming `clusterer` is your trained HDBSCAN object\n",
    "with open('bat_region_clusterer.pkl', 'wb') as f:\n",
    "    pickle.dump(clusterer, f)\n",
    "\n",
    "\n",
    "# Assign unique cluster IDs to noise points (-1)\n",
    "noise_points = np.where(labels == -1)[0]\n",
    "max_label = labels.max()\n",
    "\n",
    "for i, idx in enumerate(noise_points):\n",
    "    labels[idx] = max_label + 1 + i\n",
    "\n",
    "gdf_utm['region_id'] = labels\n",
    "\n",
    "bat['region_id'] = gdf_utm['region_id']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:55.771149Z",
     "start_time": "2025-06-15T02:54:55.694460Z"
    }
   },
   "id": "f6f88f60e6f2018e"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Brown hare region clustering\n",
    "gdf_brown_hare = gpd.GeoDataFrame(brown_hare, geometry=gpd.points_from_xy(brown_hare['decimalLongitude'], brown_hare['decimalLatitude']), crs='EPSG:4326')\n",
    "utm_crs_brown_hare = CRS(\"EPSG:32630\")\n",
    "gdf_brown_hare_utm = gdf_brown_hare.to_crs(utm_crs_brown_hare)\n",
    "# Extract UTM X/Y for clustering\n",
    "coords_utm_brown_hare = gdf_brown_hare_utm.geometry.apply(lambda p: (p.x, p.y)).to_list()\n",
    "# HDBSCAN clustering\n",
    "clusterer_brown_hare = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,       # ensures even sparse regions form clusters\n",
    "    min_samples=1,\n",
    "    cluster_selection_epsilon=800.0,  # 800 meters\n",
    "    metric='euclidean'  # Now in meters, not degrees\n",
    ")\n",
    "# Fit and assign region IDs\n",
    "labels_brown_hare = clusterer_brown_hare.fit_predict(np.array(coords_utm_brown_hare))\n",
    "# Assuming `clusterer_brown_hare` is your trained HDBSCAN object\n",
    "with open('brown_hare_region_clusterer.pkl', 'wb') as f:\n",
    "    pickle.dump(clusterer_brown_hare, f)\n",
    "# Assign unique cluster IDs to noise points (-1)\n",
    "noise_points_brown_hare = np.where(labels_brown_hare == -1)[0]\n",
    "max_label_brown_hare = labels_brown_hare.max()\n",
    "for i, idx in enumerate(noise_points_brown_hare):\n",
    "    labels_brown_hare[idx] = max_label_brown_hare + 1 + i\n",
    "gdf_brown_hare_utm['region_id'] = labels_brown_hare\n",
    "brown_hare['region_id'] = gdf_brown_hare_utm['region_id']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:56.045190Z",
     "start_time": "2025-06-15T02:54:55.828199Z"
    }
   },
   "id": "6f42badbbc421707"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dormice region clustering\n",
    "gdf_dormice = gpd.GeoDataFrame(dormice, geometry=gpd.points_from_xy(dormice['decimalLongitude'], dormice['decimalLatitude']), crs='EPSG:4326')\n",
    "utm_crs_dormice = CRS(\"EPSG:32630\")\n",
    "gdf_dormice_utm = gdf_dormice.to_crs(utm_crs_dormice)\n",
    "# Extract UTM X/Y for clustering\n",
    "coords_utm_dormice = gdf_dormice_utm.geometry.apply(lambda p: (p.x, p.y)).to_list()\n",
    "# HDBSCAN clustering\n",
    "clusterer_dormice = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,       # ensures even sparse regions form clusters\n",
    "    min_samples=1,\n",
    "    cluster_selection_epsilon=800.0,  # 800 meters\n",
    "    metric='euclidean'  # Now in meters, not degrees\n",
    ")\n",
    "# Fit and assign region IDs\n",
    "labels_dormice = clusterer_dormice.fit_predict(np.array(coords_utm_dormice))\n",
    "# Assuming `clusterer_dormice` is your trained HDBSCAN object\n",
    "with open('dormice_region_clusterer.pkl', 'wb') as f:\n",
    "    pickle.dump(clusterer_dormice, f)\n",
    "# Assign unique cluster IDs to noise points (-1)\n",
    "noise_points_dormice = np.where(labels_dormice == -1)[0]\n",
    "max_label_dormice = labels_dormice.max()\n",
    "for i, idx in enumerate(noise_points_dormice):\n",
    "    labels_dormice[idx] = max_label_dormice + 1 + i\n",
    "gdf_dormice_utm['region_id'] = labels_dormice\n",
    "dormice['region_id'] = gdf_dormice_utm['region_id']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:56.159821Z",
     "start_time": "2025-06-15T02:54:56.047015Z"
    }
   },
   "id": "506c970f981fe844"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hedgehog region clustering\n",
    "gdf_hedgehog = gpd.GeoDataFrame(hedgehog, geometry=gpd.points_from_xy(hedgehog['decimalLongitude'], hedgehog['decimalLatitude']), crs='EPSG:4326')\n",
    "utm_crs_hedgehog = CRS(\"EPSG:32630\")\n",
    "gdf_hedgehog_utm = gdf_hedgehog.to_crs(utm_crs_hedgehog)\n",
    "# Extract UTM X/Y for clustering\n",
    "coords_utm_hedgehog = gdf_hedgehog_utm.geometry.apply(lambda p: (p.x, p.y)).to_list()\n",
    "# HDBSCAN clustering\n",
    "clusterer_hedgehog = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,       # ensures even sparse regions form clusters\n",
    "    min_samples=1,\n",
    "    cluster_selection_epsilon=800.0,  # 800 meters\n",
    "    metric='euclidean'  # Now in meters, not degrees\n",
    ")\n",
    "# Fit and assign region IDs\n",
    "labels_hedgehog = clusterer_hedgehog.fit_predict(np.array(coords_utm_hedgehog))\n",
    "# Assuming `clusterer_hedgehog` is your trained HDBSCAN object\n",
    "with open('hedgehog_region_clusterer.pkl', 'wb') as f:\n",
    "    pickle.dump(clusterer_hedgehog, f)\n",
    "# Assign unique cluster IDs to noise points (-1)\n",
    "noise_points_hedgehog = np.where(labels_hedgehog == -1)[0]\n",
    "max_label_hedgehog = labels_hedgehog.max()\n",
    "for i, idx in enumerate(noise_points_hedgehog):\n",
    "    labels_hedgehog[idx] = max_label_hedgehog + 1 + i\n",
    "gdf_hedgehog_utm['region_id'] = labels_hedgehog\n",
    "hedgehog['region_id'] = gdf_hedgehog_utm['region_id']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:54:58.549739Z",
     "start_time": "2025-06-15T02:54:56.158797Z"
    }
   },
   "id": "6a66e2ff4e33b419"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/arzaan/PycharmProjects/ComputationalIntelligence/venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Red squirrel region clustering\n",
    "gdf_red_squirrel = gpd.GeoDataFrame(red_squirrel, geometry=gpd.points_from_xy(red_squirrel['decimalLongitude'], red_squirrel['decimalLatitude']), crs='EPSG:4326')\n",
    "utm_crs_red_squirrel = CRS(\"EPSG:32630\")\n",
    "gdf_red_squirrel_utm = gdf_red_squirrel.to_crs(utm_crs_red_squirrel)\n",
    "# Extract UTM X/Y for clustering\n",
    "coords_utm_red_squirrel = gdf_red_squirrel_utm.geometry.apply(lambda p: (p.x, p.y)).to_list()\n",
    "# HDBSCAN clustering\n",
    "clusterer_red_squirrel = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,       # ensures even sparse regions form clusters\n",
    "    min_samples=1,\n",
    "    cluster_selection_epsilon=800.0,  # 800 meters\n",
    "    metric='euclidean'  # Now in meters, not degrees\n",
    ")\n",
    "# Fit and assign region IDs\n",
    "labels_red_squirrel = clusterer_red_squirrel.fit_predict(np.array(coords_utm_red_squirrel))\n",
    "# Assuming `clusterer_red_squirrel` is your trained HDBSCAN object\n",
    "with open('red_squirrel_region_clusterer.pkl', 'wb') as f:\n",
    "    pickle.dump(clusterer_red_squirrel, f)\n",
    "# Assign unique cluster IDs to noise points (-1)\n",
    "noise_points_red_squirrel = np.where(labels_red_squirrel == -1)[0]\n",
    "max_label_red_squirrel = labels_red_squirrel.max()\n",
    "for i, idx in enumerate(noise_points_red_squirrel):\n",
    "    labels_red_squirrel[idx] = max_label_red_squirrel + 1 + i\n",
    "gdf_red_squirrel_utm['region_id'] = labels_red_squirrel\n",
    "red_squirrel['region_id'] = gdf_red_squirrel_utm['region_id']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:55:00.275105Z",
     "start_time": "2025-06-15T02:54:58.537727Z"
    }
   },
   "id": "408ccaac4c2992c2"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# drop lat/long columns\n",
    "bat = bat.drop(columns=['decimalLatitude', 'decimalLongitude'])\n",
    "brown_hare = brown_hare.drop(columns=['decimalLatitude', 'decimalLongitude'])\n",
    "dormice = dormice.drop(columns=['decimalLatitude', 'decimalLongitude'])\n",
    "hedgehog = hedgehog.drop(columns=['decimalLatitude', 'decimalLongitude'])\n",
    "red_squirrel = red_squirrel.drop(columns=['decimalLatitude', 'decimalLongitude'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:55:00.284283Z",
     "start_time": "2025-06-15T02:55:00.274403Z"
    }
   },
   "id": "5a6cb05376081409"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "env_vars = ['BSI', 'LST', 'MNDWI', 'NDBI', 'NDSI', 'NDVI', 'NDWI', 'SAVI', 'UI']\n",
    "bat[env_vars] = scaler.fit_transform(bat[env_vars])\n",
    "# save the scaler\n",
    "with open('bat_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "brown_hare[env_vars] = scaler.fit_transform(brown_hare[env_vars])\n",
    "# save the scaler\n",
    "with open('brown_hare_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "dormice[env_vars] = scaler.fit_transform(dormice[env_vars])\n",
    "# save the scaler\n",
    "with open('dormice_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "hedgehog[env_vars] = scaler.fit_transform(hedgehog[env_vars])\n",
    "# save the scaler\n",
    "with open('hedgehog_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "red_squirrel[env_vars] = scaler.fit_transform(red_squirrel[env_vars])\n",
    "# save the scaler\n",
    "with open('red_squirrel_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:55:00.300962Z",
     "start_time": "2025-06-15T02:55:00.286110Z"
    }
   },
   "id": "b5b8047fd8af3a8"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "bat_bool_columns = ['ceratopogonidae_presence','chironomidae_presence','cats_presence','wind_turbines_presence','near_road']\n",
    "dormice_bool_columns = ['hazel_presence','birch_presence','beech_presence','honeysuckle_presence','oak_presence','hawthorn_presence']\n",
    "hedgehog_bool_columns = ['badger_presence','ground_beetles_presence','near_road']\n",
    "brown_hare_bool_columns = ['winter_wheat_presence']\n",
    "red_squirrel_bool_columns = ['sitka_spruce_presence','grey_squirrel_presence']\n",
    "\n",
    "bat[bat_bool_columns] = bat[bat_bool_columns].astype(bool)\n",
    "dormice[dormice_bool_columns] = dormice[dormice_bool_columns].astype(bool)\n",
    "hedgehog[hedgehog_bool_columns] = hedgehog[hedgehog_bool_columns].astype(bool)\n",
    "brown_hare[brown_hare_bool_columns] = brown_hare[brown_hare_bool_columns].astype(bool)\n",
    "red_squirrel[red_squirrel_bool_columns] = red_squirrel[red_squirrel_bool_columns].astype(bool)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:57:42.493964Z",
     "start_time": "2025-06-15T02:57:42.483591Z"
    }
   },
   "id": "45d3acf7b5b51146"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "bat = pd.get_dummies(bat, columns=['Land_cover'])\n",
    "brown_hare = pd.get_dummies(brown_hare, columns=['Land_cover'])\n",
    "dormice = pd.get_dummies(dormice, columns=['Land_cover'])\n",
    "hedgehog = pd.get_dummies(hedgehog, columns=['Land_cover'])\n",
    "red_squirrel = pd.get_dummies(red_squirrel, columns=['Land_cover'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:57:59.676695Z",
     "start_time": "2025-06-15T02:57:59.618975Z"
    }
   },
   "id": "6a2388619d51d57d"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "            BSI       LST     MNDWI      NDBI      NDSI      NDVI      NDWI  \\\n0      1.395999  0.704739  1.190194  0.318967  1.190194 -1.428353  1.528635   \n1     -0.444714  0.492250 -0.071536 -0.805157 -0.071536  0.663558 -0.506304   \n2      2.252173  0.519514  1.990485  0.134052  1.990485 -2.388220  2.460455   \n3     -0.399284  0.433378 -0.083044 -0.347021 -0.083044  0.451493 -0.113816   \n4     -0.431666 -0.233311 -0.929215  1.443395 -0.929215 -0.310041 -0.486236   \n...         ...       ...       ...       ...       ...       ...       ...   \n37488  0.820917  0.791313  0.616713  0.497967  0.616713 -0.828457  0.922715   \n37489  2.467499  1.405014  2.403377 -0.542954  2.403377 -2.457251  2.586302   \n37490 -1.075908  0.502881 -0.824936 -0.440819 -0.824936  1.245877 -1.063531   \n37491  0.049248  1.203749 -0.271477  1.400403 -0.271477 -0.470055  0.390742   \n37492  0.642698  0.040936  0.726081 -0.211070  0.726081 -0.465051  0.628611   \n\n           SAVI        UI  sitka_spruce_presence  ...  Land_cover_Inland rock  \\\n0     -1.428620 -0.318967                  False  ...                   False   \n1      0.663807  0.805157                  False  ...                   False   \n2     -2.388818 -0.134052                  False  ...                   False   \n3      0.451885  0.347021                  False  ...                   False   \n4     -0.311057 -1.443395                  False  ...                   False   \n...         ...       ...                    ...  ...                     ...   \n37488 -0.828659 -0.497967                  False  ...                   False   \n37489 -2.457876  0.542954                  False  ...                   False   \n37490  1.246321  0.440819                  False  ...                   False   \n37491 -0.470308 -1.400403                  False  ...                   False   \n37492 -0.465332  0.211070                  False  ...                   False   \n\n       Land_cover_Littoral rock  Land_cover_Littoral sediment  \\\n0                         False                         False   \n1                         False                         False   \n2                         False                         False   \n3                         False                         False   \n4                         False                         False   \n...                         ...                           ...   \n37488                     False                         False   \n37489                     False                         False   \n37490                     False                         False   \n37491                     False                         False   \n37492                     False                         False   \n\n       Land_cover_Neutral grassland  Land_cover_Saltmarsh  \\\n0                             False                 False   \n1                             False                 False   \n2                             False                 False   \n3                             False                 False   \n4                             False                 False   \n...                             ...                   ...   \n37488                         False                 False   \n37489                         False                 False   \n37490                         False                 False   \n37491                         False                 False   \n37492                         False                 False   \n\n       Land_cover_Saltwater  Land_cover_Suburban  \\\n0                     False                False   \n1                     False                False   \n2                     False                False   \n3                     False                 True   \n4                     False                False   \n...                     ...                  ...   \n37488                 False                False   \n37489                 False                False   \n37490                 False                False   \n37491                 False                 True   \n37492                 False                False   \n\n       Land_cover_Supralittoral rock  Land_cover_Supralittoral sediment  \\\n0                              False                              False   \n1                              False                              False   \n2                              False                              False   \n3                              False                              False   \n4                              False                              False   \n...                              ...                                ...   \n37488                          False                              False   \n37489                          False                              False   \n37490                          False                              False   \n37491                          False                              False   \n37492                          False                              False   \n\n       Land_cover_Urban  \n0                 False  \n1                 False  \n2                 False  \n3                 False  \n4                 False  \n...                 ...  \n37488             False  \n37489             False  \n37490             False  \n37491             False  \n37492              True  \n\n[36447 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BSI</th>\n      <th>LST</th>\n      <th>MNDWI</th>\n      <th>NDBI</th>\n      <th>NDSI</th>\n      <th>NDVI</th>\n      <th>NDWI</th>\n      <th>SAVI</th>\n      <th>UI</th>\n      <th>sitka_spruce_presence</th>\n      <th>...</th>\n      <th>Land_cover_Inland rock</th>\n      <th>Land_cover_Littoral rock</th>\n      <th>Land_cover_Littoral sediment</th>\n      <th>Land_cover_Neutral grassland</th>\n      <th>Land_cover_Saltmarsh</th>\n      <th>Land_cover_Saltwater</th>\n      <th>Land_cover_Suburban</th>\n      <th>Land_cover_Supralittoral rock</th>\n      <th>Land_cover_Supralittoral sediment</th>\n      <th>Land_cover_Urban</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.395999</td>\n      <td>0.704739</td>\n      <td>1.190194</td>\n      <td>0.318967</td>\n      <td>1.190194</td>\n      <td>-1.428353</td>\n      <td>1.528635</td>\n      <td>-1.428620</td>\n      <td>-0.318967</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.444714</td>\n      <td>0.492250</td>\n      <td>-0.071536</td>\n      <td>-0.805157</td>\n      <td>-0.071536</td>\n      <td>0.663558</td>\n      <td>-0.506304</td>\n      <td>0.663807</td>\n      <td>0.805157</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.252173</td>\n      <td>0.519514</td>\n      <td>1.990485</td>\n      <td>0.134052</td>\n      <td>1.990485</td>\n      <td>-2.388220</td>\n      <td>2.460455</td>\n      <td>-2.388818</td>\n      <td>-0.134052</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.399284</td>\n      <td>0.433378</td>\n      <td>-0.083044</td>\n      <td>-0.347021</td>\n      <td>-0.083044</td>\n      <td>0.451493</td>\n      <td>-0.113816</td>\n      <td>0.451885</td>\n      <td>0.347021</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.431666</td>\n      <td>-0.233311</td>\n      <td>-0.929215</td>\n      <td>1.443395</td>\n      <td>-0.929215</td>\n      <td>-0.310041</td>\n      <td>-0.486236</td>\n      <td>-0.311057</td>\n      <td>-1.443395</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37488</th>\n      <td>0.820917</td>\n      <td>0.791313</td>\n      <td>0.616713</td>\n      <td>0.497967</td>\n      <td>0.616713</td>\n      <td>-0.828457</td>\n      <td>0.922715</td>\n      <td>-0.828659</td>\n      <td>-0.497967</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>37489</th>\n      <td>2.467499</td>\n      <td>1.405014</td>\n      <td>2.403377</td>\n      <td>-0.542954</td>\n      <td>2.403377</td>\n      <td>-2.457251</td>\n      <td>2.586302</td>\n      <td>-2.457876</td>\n      <td>0.542954</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>37490</th>\n      <td>-1.075908</td>\n      <td>0.502881</td>\n      <td>-0.824936</td>\n      <td>-0.440819</td>\n      <td>-0.824936</td>\n      <td>1.245877</td>\n      <td>-1.063531</td>\n      <td>1.246321</td>\n      <td>0.440819</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>37491</th>\n      <td>0.049248</td>\n      <td>1.203749</td>\n      <td>-0.271477</td>\n      <td>1.400403</td>\n      <td>-0.271477</td>\n      <td>-0.470055</td>\n      <td>0.390742</td>\n      <td>-0.470308</td>\n      <td>-1.400403</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>37492</th>\n      <td>0.642698</td>\n      <td>0.040936</td>\n      <td>0.726081</td>\n      <td>-0.211070</td>\n      <td>0.726081</td>\n      <td>-0.465051</td>\n      <td>0.628611</td>\n      <td>-0.465332</td>\n      <td>0.211070</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>36447 rows × 35 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_squirrel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:58:24.544942Z",
     "start_time": "2025-06-15T02:58:24.529877Z"
    }
   },
   "id": "bc020834e41f912b"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# save the dataframes\n",
    "bat.to_csv('bat_final_data_preprocessed.csv', index=False)\n",
    "brown_hare.to_csv('brown_hare_final_data_preprocessed.csv', index=False)\n",
    "dormice.to_csv('dormice_final_data_preprocessed.csv', index=False)\n",
    "hedgehog.to_csv('hedgehog_final_data_preprocessed.csv', index=False)\n",
    "red_squirrel.to_csv('red_squirrel_final_data_preprocessed.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T02:59:26.876294Z",
     "start_time": "2025-06-15T02:59:25.547518Z"
    }
   },
   "id": "5e499aa7ede0c614"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7bbaeb17b719468d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
