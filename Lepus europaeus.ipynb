{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:27:40.911105Z",
     "start_time": "2025-08-05T23:27:38.138149Z"
    }
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "ee.Initialize(project='ee-arzaaan789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/sggn66691kd6g5mtyzpq2hv80000gn/T/ipykernel_84512/3337580572.py:4: DtypeWarning: Columns (10,39,41,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Lepus europaeus.csv\", delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"Lepus europaeus.csv\", delimiter='\\t')\n",
    "df = df[df[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "df = df[df['year']>=2022]\n",
    "# df['eventDate'] = df['eventDate'].str.replace('/','')\n",
    "df['eventDate'] = pd.to_datetime(df['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "df = df[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "df = df.dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:27:44.499037Z",
     "start_time": "2025-08-05T23:27:43.086407Z"
    }
   },
   "id": "ea1f21080951b06"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 204/204 [19:37<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           species  decimalLatitude  decimalLongitude  eventDate       BSI  \\\n",
      "0  Lepus europaeus        52.746722         -1.038527 2022-10-09 -0.699341   \n",
      "1  Lepus europaeus        52.819095         -1.096287 2022-07-20 -0.654526   \n",
      "2  Lepus europaeus        52.583645         -0.894504 2022-05-10 -0.491253   \n",
      "3  Lepus europaeus        52.723961         -0.565204 2023-05-01 -0.444113   \n",
      "4  Lepus europaeus        52.709478         -0.891327 2023-05-07 -0.431772   \n",
      "\n",
      "          LST     MNDWI      NDBI      NDSI      NDVI      NDWI      SAVI  \\\n",
      "0  286.446075 -0.528530 -0.189280 -0.528530  0.684339 -0.650132  1.026362   \n",
      "1  303.545778 -0.560384 -0.106128 -0.560384  0.603091 -0.628835  0.904530   \n",
      "2  292.681717 -0.169483 -0.423198 -0.169483  0.629200 -0.553601  0.943726   \n",
      "3  288.931470 -0.165867 -0.363490 -0.165867  0.547637 -0.499577  0.821378   \n",
      "4  289.501750 -0.191123 -0.337865 -0.191123  0.546665 -0.486093  0.819932   \n",
      "\n",
      "         UI  \n",
      "0  0.189280  \n",
      "1  0.106128  \n",
      "2  0.423198  \n",
      "3  0.363490  \n",
      "4  0.337865  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ee.Initialize()\n",
    "\n",
    "# Your dataframe 'df' must have columns: decimalLongitude, decimalLatitude\n",
    "# Example: df = pd.read_csv(\"Erinaceus europaeus.csv\", delimiter='\\t')\n",
    "\n",
    "def create_aoi(lon, lat, box_size_km=1):\n",
    "    \"\"\"Create approx 1km x 1km square polygon around lon, lat.\"\"\"\n",
    "    half_side_deg = box_size_km / 111.32 / 2  # Rough approx degrees per km\n",
    "\n",
    "    coords = [\n",
    "        [lon - half_side_deg, lat - half_side_deg],\n",
    "        [lon + half_side_deg, lat - half_side_deg],\n",
    "        [lon + half_side_deg, lat + half_side_deg],\n",
    "        [lon - half_side_deg, lat + half_side_deg],\n",
    "        [lon - half_side_deg, lat - half_side_deg]\n",
    "    ]\n",
    "    return ee.Geometry.Polygon(coords)\n",
    "\n",
    "def compute_all_indices(feature, start_date, end_date):\n",
    "    \"\"\"Compute spectral indices and LST for one EE Feature (with AOI geometry).\"\"\"\n",
    "    aoi = feature.geometry()\n",
    "\n",
    "    s2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "          .filterBounds(aoi)\n",
    "          .filterDate(start_date, end_date)\n",
    "          .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
    "          .first())\n",
    "    s2 = ee.Image(s2).clip(aoi)\n",
    "\n",
    "    blue = s2.select('B2')\n",
    "    green = s2.select('B3')\n",
    "    red = s2.select('B4')\n",
    "    nir = s2.select('B8')\n",
    "    swir = s2.select('B11')\n",
    "\n",
    "    L = 0.5  # SAVI constant\n",
    "\n",
    "    ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
    "    ndwi = green.subtract(nir).divide(green.add(nir)).rename('NDWI')\n",
    "    ndbi = swir.subtract(nir).divide(swir.add(nir)).rename('NDBI')\n",
    "    savi = nir.subtract(red).divide(nir.add(red).add(L)).multiply(1 + L).rename('SAVI')\n",
    "    mndwi = green.subtract(swir).divide(green.add(swir)).rename('MNDWI')\n",
    "    ndsi = green.subtract(swir).divide(green.add(swir)).rename('NDSI')\n",
    "    bsi = (red.add(blue).subtract(nir.add(swir))).divide(red.add(blue).add(nir).add(swir)).rename('BSI')\n",
    "    ui = nir.subtract(swir).divide(nir.add(swir)).rename('UI')\n",
    "\n",
    "    reducers = ee.Reducer.mean()\n",
    "    scale_10m = 1000\n",
    "\n",
    "    ndvi_mean = ndvi.reduceRegion(reducers, aoi, scale_10m).get('NDVI')\n",
    "    ndwi_mean = ndwi.reduceRegion(reducers, aoi, scale_10m).get('NDWI')\n",
    "    ndbi_mean = ndbi.reduceRegion(reducers, aoi, scale_10m).get('NDBI')\n",
    "    savi_mean = savi.reduceRegion(reducers, aoi, scale_10m).get('SAVI')\n",
    "    mndwi_mean = mndwi.reduceRegion(reducers, aoi, scale_10m).get('MNDWI')\n",
    "    ndsi_mean = ndsi.reduceRegion(reducers, aoi, scale_10m).get('NDSI')\n",
    "    bsi_mean = bsi.reduceRegion(reducers, aoi, scale_10m).get('BSI')\n",
    "    ui_mean = ui.reduceRegion(reducers, aoi, scale_10m).get('UI')\n",
    "\n",
    "    # MODIS LST dataset\n",
    "    modis = (ee.ImageCollection(\"MODIS/061/MOD11A1\")\n",
    "             .filterBounds(aoi)\n",
    "             .filterDate(start_date, end_date)\n",
    "             .select('LST_Day_1km'))\n",
    "\n",
    "    lst_mean_img = modis.mean().multiply(0.02).clip(aoi)\n",
    "\n",
    "    lst_mean = lst_mean_img.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi,\n",
    "        scale=1000\n",
    "    ).get('LST_Day_1km')\n",
    "\n",
    "    return feature.set({\n",
    "        'NDVI': ndvi_mean,\n",
    "        'NDWI': ndwi_mean,\n",
    "        'NDBI': ndbi_mean,\n",
    "        'SAVI': savi_mean,\n",
    "        'MNDWI': mndwi_mean,\n",
    "        'NDSI': ndsi_mean,\n",
    "        'BSI': bsi_mean,\n",
    "        'UI': ui_mean,\n",
    "        'LST': lst_mean\n",
    "    })\n",
    "\n",
    "# Split df into batches\n",
    "batch_size = 50\n",
    "batches = [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "index_names = ['NDVI', 'NDWI', 'NDBI', 'SAVI', 'MNDWI', 'NDSI', 'BSI', 'UI', 'LST']\n",
    "\n",
    "for batch in tqdm(batches, desc=\"Processing batches\"):\n",
    "    features = []\n",
    "    batch_indices = []\n",
    "    feature_metadata = {}\n",
    "\n",
    "    for idx, row in batch.iterrows():\n",
    "        \n",
    "        aoi = create_aoi(row['decimalLongitude'], row['decimalLatitude'])\n",
    "        feature = ee.Feature(aoi).set('index', idx)\n",
    "        features.append(feature)\n",
    "        batch_indices.append(idx)  # Save the original index\n",
    "        \n",
    "        event_date = row['eventDate']\n",
    "        start_date = (event_date - timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "        end_date = (event_date + timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "        feature_metadata[idx] = (start_date, end_date)\n",
    "\n",
    "    # Create a FeatureCollection from the list of features\n",
    "    fc = ee.FeatureCollection(features)\n",
    "    \n",
    "    # Define wrapper for map to inject per-feature dates\n",
    "    def map_with_dates(f):\n",
    "        idx = f.get('index')\n",
    "        # Use dictionary lookup to get dates for this feature\n",
    "        date_dict = ee.Dictionary(ee.Dictionary(feature_metadata))\n",
    "        dates = ee.List(date_dict.get(ee.Number(idx)))\n",
    "        return compute_all_indices(f, dates.get(0), dates.get(1))\n",
    "\n",
    "    try:\n",
    "        result_fc = fc.map(map_with_dates)\n",
    "        results = result_fc.getInfo()\n",
    "\n",
    "        rows = []\n",
    "        for f in results['features']:\n",
    "            props = f['properties']\n",
    "            rows.append(props)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch starting at index {batch.index[0]}: {e}\")\n",
    "        # If there's an error, create placeholder rows with None\n",
    "        rows = [{'index': i, **{name: None for name in index_names}} for i in batch_indices]\n",
    "\n",
    "    batch_results_df = pd.DataFrame(rows).sort_values('index').reset_index(drop=True)\n",
    "    results_list.append(batch_results_df)\n",
    "\n",
    "# Concatenate all batches and sort by original index\n",
    "all_results_df = pd.concat(results_list).sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Merge with original df\n",
    "df_final = pd.concat([df.reset_index(drop=True), all_results_df.drop(columns=['index'])], axis=1)\n",
    "\n",
    "print(df_final.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:47:25.041403Z",
     "start_time": "2025-08-05T23:27:47.021149Z"
    }
   },
   "id": "9a2f0091bb2b4a19"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_final.to_csv('brown_hare_full_data.csv', index=False)\n",
    "# len(df)\n",
    "df = pd.read_csv(\"brown_hare_full_data.csv\")\n",
    "\n",
    "df['eventDate'] = pd.to_datetime(df['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "df = df.dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:47:25.221371Z",
     "start_time": "2025-08-05T23:47:25.037041Z"
    }
   },
   "id": "caf18d26b95b62e4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/sggn66691kd6g5mtyzpq2hv80000gn/T/ipykernel_84512/2925844888.py:1: DtypeWarning: Columns (39,41,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  winter_wheat = pd.read_csv(\"winter wheat.csv\", delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "winter_wheat = pd.read_csv(\"winter wheat.csv\", delimiter='\\t')\n",
    "winter_wheat = winter_wheat[winter_wheat[\"occurrenceStatus\"] == \"PRESENT\"]\n",
    "winter_wheat = winter_wheat[winter_wheat['year'] >= 2022]\n",
    "winter_wheat['eventDate'] = pd.to_datetime(winter_wheat['eventDate'], format='%Y-%m-%d', errors='coerce')\n",
    "winter_wheat = winter_wheat[['species', 'decimalLatitude', 'decimalLongitude', 'eventDate']]\n",
    "winter_wheat = winter_wheat.dropna().reset_index(drop=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:47:25.346471Z",
     "start_time": "2025-08-05T23:47:25.216265Z"
    }
   },
   "id": "12dcd3243a063ab2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10087/10087 [00:01<00:00, 9741.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Convert lat/lon to radians for BallTree\n",
    "brown_hare_coords = np.deg2rad(df[['decimalLatitude', 'decimalLongitude']].values)\n",
    "winter_wheat_coords = np.deg2rad(winter_wheat[['decimalLatitude', 'decimalLongitude']].values)\n",
    "\n",
    "# Build BallTree using haversine metric\n",
    "tree = BallTree(winter_wheat_coords, metric='haversine')\n",
    "\n",
    "# Define search radius: 1 km in radians\n",
    "earth_radius_km = 6371.0\n",
    "radius = 1 / earth_radius_km  # 1 km in radians\n",
    "\n",
    "# Initialize presence columns\n",
    "df['winter_wheat_presence'] = 0\n",
    "\n",
    "# Iterate through each brown hare point with tqdm for progress tracking\n",
    "for i in tqdm(range(len(df))):\n",
    "    point = brown_hare_coords[i].reshape(1, -1)\n",
    "    event_month = df.loc[i, 'eventDate'].month\n",
    "    event_year = df.loc[i, 'eventDate'].year\n",
    "\n",
    "    # WINTER WHEAT\n",
    "    idxs = tree.query_radius(point, r=radius)[0]\n",
    "    for j in idxs:\n",
    "        winter_wheat_date = winter_wheat.loc[j, 'eventDate']\n",
    "        if winter_wheat_date.month == event_month and winter_wheat_date.year == event_year:\n",
    "            df.at[i, 'winter_wheat_presence'] = 1\n",
    "            break  # Found at least one match, no need to check further"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:47:29.436449Z",
     "start_time": "2025-08-05T23:47:25.352030Z"
    }
   },
   "id": "308dae4a55d5361c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10087/10087 [04:15<00:00, 39.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "from rasterio.windows import Window\n",
    "import rasterio\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "land_cover_map = {\n",
    "    1: \"Deciduous woodland\",\n",
    "    2: \"Coniferous woodland\",\n",
    "    3: \"Arable\",\n",
    "    4: \"Improved grassland\",\n",
    "    5: \"Neutral grassland\",\n",
    "    6: \"Calcareous grassland\",\n",
    "    7: \"Acid grassland\",\n",
    "    8: \"Fen\",\n",
    "    9: \"Heather\",\n",
    "    10: \"Heather grassland\",\n",
    "    11: \"Bog\",\n",
    "    12: \"Inland rock\",\n",
    "    13: \"Saltwater\",\n",
    "    14: \"Freshwater\",\n",
    "    15: \"Supralittoral rock\",\n",
    "    16: \"Supralittoral sediment\",\n",
    "    17: \"Littoral rock\",\n",
    "    18: \"Littoral sediment\",\n",
    "    19: \"Saltmarsh\",\n",
    "    20: \"Urban\",\n",
    "    21: \"Suburban\"\n",
    "}\n",
    "\n",
    "# Batch coordinate transformation\n",
    "transformer_ni = Transformer.from_crs(\"EPSG:4326\", \"EPSG:29903\", always_xy=True)\n",
    "transformer_gb = Transformer.from_crs(\"EPSG:4326\", \"EPSG:27700\", always_xy=True)\n",
    "\n",
    "coords = list(zip(df['decimalLongitude'], df['decimalLatitude']))\n",
    "df['easting_ni'], df['northing_ni'] = zip(*transformer_ni.itransform(coords))\n",
    "df['easting_gb'], df['northing_gb'] = zip(*transformer_gb.itransform(coords))\n",
    "\n",
    "# Raster processing optimization\n",
    "gb_raster = 'gblcm2023_10m.tif'\n",
    "n_ireland_raster = 'nilcm2023_10m.tif'\n",
    "\n",
    "\n",
    "def get_land_cover_class_1km(row):\n",
    "    try:\n",
    "        window_size_pixels = 100  # 1 km / 10m resolution\n",
    "\n",
    "        # Open GB raster and read 1km x 1km window\n",
    "        with rasterio.open(gb_raster) as src:\n",
    "            row_idx, col_idx = src.index(row['easting_gb'], row['northing_gb'])\n",
    "\n",
    "            # Calculate window bounds, making sure not to go out of raster bounds\n",
    "            row_start = max(row_idx - window_size_pixels // 2, 0)\n",
    "            col_start = max(col_idx - window_size_pixels // 2, 0)\n",
    "\n",
    "            # Adjust window size if near edges\n",
    "            height = min(window_size_pixels, src.height - row_start)\n",
    "            width = min(window_size_pixels, src.width - col_start)\n",
    "\n",
    "            window = Window(col_start, row_start, width, height)\n",
    "            data = src.read(1, window=window)\n",
    "\n",
    "            # If all zero (or no data), fallback to NI raster\n",
    "            if np.all(data == 0):\n",
    "                with rasterio.open(n_ireland_raster) as src_ni:\n",
    "                    row_idx_ni, col_idx_ni = src_ni.index(row['easting_ni'], row['northing_ni'])\n",
    "\n",
    "                    row_start_ni = max(row_idx_ni - window_size_pixels // 2, 0)\n",
    "                    col_start_ni = max(col_idx_ni - window_size_pixels // 2, 0)\n",
    "\n",
    "                    height_ni = min(window_size_pixels, src_ni.height - row_start_ni)\n",
    "                    width_ni = min(window_size_pixels, src_ni.width - col_start_ni)\n",
    "\n",
    "                    window_ni = Window(col_start_ni, row_start_ni, width_ni, height_ni)\n",
    "                    data_ni = src_ni.read(1, window=window_ni)\n",
    "\n",
    "                    data = data_ni\n",
    "\n",
    "            # Find the most common class (mode) ignoring zeros (assuming 0 means no data)\n",
    "            unique, counts = np.unique(data[data != 0], return_counts=True)\n",
    "            if len(counts) == 0:\n",
    "                return \"Unknown\"\n",
    "\n",
    "            mode_class = unique[np.argmax(counts)]\n",
    "            return land_cover_map.get(mode_class, \"Unknown\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "df['Land_cover'] = df.progress_apply(get_land_cover_class_1km, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:51:44.090500Z",
     "start_time": "2025-08-05T23:47:27.889385Z"
    }
   },
   "id": "3d85f9ecfe7c141f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               species  decimalLatitude  decimalLongitude  eventDate  \\\n0      Lepus europaeus        52.746722         -1.038527 2022-10-09   \n1      Lepus europaeus        52.819095         -1.096287 2022-07-20   \n2      Lepus europaeus        52.583645         -0.894504 2022-05-10   \n3      Lepus europaeus        52.723961         -0.565204 2023-05-01   \n4      Lepus europaeus        52.709478         -0.891327 2023-05-07   \n...                ...              ...               ...        ...   \n10082  Lepus europaeus        55.267030         -1.624645 2022-02-07   \n10083  Lepus europaeus        54.977467         -1.919587 2024-05-11   \n10084  Lepus europaeus        55.272401         -1.618299 2022-02-07   \n10085  Lepus europaeus        55.261713         -1.649871 2023-02-09   \n10086  Lepus europaeus        54.387635         -0.743331 2024-08-04   \n\n            BSI         LST     MNDWI      NDBI      NDSI      NDVI      NDWI  \\\n0     -0.699341  286.446075 -0.528530 -0.189280 -0.528530  0.684339 -0.650132   \n1     -0.654526  303.545778 -0.560384 -0.106128 -0.560384  0.603091 -0.628835   \n2     -0.491253  292.681717 -0.169483 -0.423198 -0.169483  0.629200 -0.553601   \n3     -0.444113  288.931470 -0.165867 -0.363490 -0.165867  0.547637 -0.499577   \n4     -0.431772  289.501750 -0.191123 -0.337865 -0.191123  0.546665 -0.486093   \n...         ...         ...       ...       ...       ...       ...       ...   \n10082 -0.583027  278.794319 -0.526633 -0.107525 -0.526633  0.526273 -0.599162   \n10083 -0.645504  292.649449 -0.417604 -0.296257 -0.417604  0.696344 -0.634863   \n10084 -0.516168  278.878166 -0.459324 -0.098333 -0.459324  0.467266 -0.529902   \n10085 -0.636645  278.456060 -0.421279 -0.249452 -0.421279  0.644174 -0.605173   \n10086 -0.109021  293.962762 -0.033491 -0.141657 -0.033491  0.180639 -0.174197   \n\n           SAVI        UI  winter_wheat_presence          Land_cover  \n0      1.026362  0.189280                      0              Arable  \n1      0.904530  0.106128                      0  Improved grassland  \n2      0.943726  0.423198                      0  Improved grassland  \n3      0.821378  0.363490                      0              Arable  \n4      0.819932  0.337865                      0  Improved grassland  \n...         ...       ...                    ...                 ...  \n10082  0.789296  0.107525                      0              Arable  \n10083  1.044399  0.296257                      0              Arable  \n10084  0.700772  0.098333                      0  Deciduous woodland  \n10085  0.966133  0.249452                      0              Arable  \n10086  0.270946  0.141657                      0  Improved grassland  \n\n[10087 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>species</th>\n      <th>decimalLatitude</th>\n      <th>decimalLongitude</th>\n      <th>eventDate</th>\n      <th>BSI</th>\n      <th>LST</th>\n      <th>MNDWI</th>\n      <th>NDBI</th>\n      <th>NDSI</th>\n      <th>NDVI</th>\n      <th>NDWI</th>\n      <th>SAVI</th>\n      <th>UI</th>\n      <th>winter_wheat_presence</th>\n      <th>Land_cover</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lepus europaeus</td>\n      <td>52.746722</td>\n      <td>-1.038527</td>\n      <td>2022-10-09</td>\n      <td>-0.699341</td>\n      <td>286.446075</td>\n      <td>-0.528530</td>\n      <td>-0.189280</td>\n      <td>-0.528530</td>\n      <td>0.684339</td>\n      <td>-0.650132</td>\n      <td>1.026362</td>\n      <td>0.189280</td>\n      <td>0</td>\n      <td>Arable</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lepus europaeus</td>\n      <td>52.819095</td>\n      <td>-1.096287</td>\n      <td>2022-07-20</td>\n      <td>-0.654526</td>\n      <td>303.545778</td>\n      <td>-0.560384</td>\n      <td>-0.106128</td>\n      <td>-0.560384</td>\n      <td>0.603091</td>\n      <td>-0.628835</td>\n      <td>0.904530</td>\n      <td>0.106128</td>\n      <td>0</td>\n      <td>Improved grassland</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lepus europaeus</td>\n      <td>52.583645</td>\n      <td>-0.894504</td>\n      <td>2022-05-10</td>\n      <td>-0.491253</td>\n      <td>292.681717</td>\n      <td>-0.169483</td>\n      <td>-0.423198</td>\n      <td>-0.169483</td>\n      <td>0.629200</td>\n      <td>-0.553601</td>\n      <td>0.943726</td>\n      <td>0.423198</td>\n      <td>0</td>\n      <td>Improved grassland</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lepus europaeus</td>\n      <td>52.723961</td>\n      <td>-0.565204</td>\n      <td>2023-05-01</td>\n      <td>-0.444113</td>\n      <td>288.931470</td>\n      <td>-0.165867</td>\n      <td>-0.363490</td>\n      <td>-0.165867</td>\n      <td>0.547637</td>\n      <td>-0.499577</td>\n      <td>0.821378</td>\n      <td>0.363490</td>\n      <td>0</td>\n      <td>Arable</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lepus europaeus</td>\n      <td>52.709478</td>\n      <td>-0.891327</td>\n      <td>2023-05-07</td>\n      <td>-0.431772</td>\n      <td>289.501750</td>\n      <td>-0.191123</td>\n      <td>-0.337865</td>\n      <td>-0.191123</td>\n      <td>0.546665</td>\n      <td>-0.486093</td>\n      <td>0.819932</td>\n      <td>0.337865</td>\n      <td>0</td>\n      <td>Improved grassland</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10082</th>\n      <td>Lepus europaeus</td>\n      <td>55.267030</td>\n      <td>-1.624645</td>\n      <td>2022-02-07</td>\n      <td>-0.583027</td>\n      <td>278.794319</td>\n      <td>-0.526633</td>\n      <td>-0.107525</td>\n      <td>-0.526633</td>\n      <td>0.526273</td>\n      <td>-0.599162</td>\n      <td>0.789296</td>\n      <td>0.107525</td>\n      <td>0</td>\n      <td>Arable</td>\n    </tr>\n    <tr>\n      <th>10083</th>\n      <td>Lepus europaeus</td>\n      <td>54.977467</td>\n      <td>-1.919587</td>\n      <td>2024-05-11</td>\n      <td>-0.645504</td>\n      <td>292.649449</td>\n      <td>-0.417604</td>\n      <td>-0.296257</td>\n      <td>-0.417604</td>\n      <td>0.696344</td>\n      <td>-0.634863</td>\n      <td>1.044399</td>\n      <td>0.296257</td>\n      <td>0</td>\n      <td>Arable</td>\n    </tr>\n    <tr>\n      <th>10084</th>\n      <td>Lepus europaeus</td>\n      <td>55.272401</td>\n      <td>-1.618299</td>\n      <td>2022-02-07</td>\n      <td>-0.516168</td>\n      <td>278.878166</td>\n      <td>-0.459324</td>\n      <td>-0.098333</td>\n      <td>-0.459324</td>\n      <td>0.467266</td>\n      <td>-0.529902</td>\n      <td>0.700772</td>\n      <td>0.098333</td>\n      <td>0</td>\n      <td>Deciduous woodland</td>\n    </tr>\n    <tr>\n      <th>10085</th>\n      <td>Lepus europaeus</td>\n      <td>55.261713</td>\n      <td>-1.649871</td>\n      <td>2023-02-09</td>\n      <td>-0.636645</td>\n      <td>278.456060</td>\n      <td>-0.421279</td>\n      <td>-0.249452</td>\n      <td>-0.421279</td>\n      <td>0.644174</td>\n      <td>-0.605173</td>\n      <td>0.966133</td>\n      <td>0.249452</td>\n      <td>0</td>\n      <td>Arable</td>\n    </tr>\n    <tr>\n      <th>10086</th>\n      <td>Lepus europaeus</td>\n      <td>54.387635</td>\n      <td>-0.743331</td>\n      <td>2024-08-04</td>\n      <td>-0.109021</td>\n      <td>293.962762</td>\n      <td>-0.033491</td>\n      <td>-0.141657</td>\n      <td>-0.033491</td>\n      <td>0.180639</td>\n      <td>-0.174197</td>\n      <td>0.270946</td>\n      <td>0.141657</td>\n      <td>0</td>\n      <td>Improved grassland</td>\n    </tr>\n  </tbody>\n</table>\n<p>10087 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df=df.drop(['easting_ni', 'northing_ni', 'easting_gb', 'northing_gb'],axis=1)\n",
    "# Remove where Land_cover is Unknown\n",
    "df = df[df['Land_cover'] != \"Unknown\"].reset_index(drop=True)\n",
    "df.to_csv(\"brown_hare_final_data.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T23:51:44.572028Z",
     "start_time": "2025-08-05T23:51:44.128400Z"
    }
   },
   "id": "dc73b404d58c82e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "80713f4980fe9919"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
